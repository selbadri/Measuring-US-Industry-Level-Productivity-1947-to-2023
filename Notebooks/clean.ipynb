{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "897f35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "fce4feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set directory for input files\n",
    "import_file_path = r\"C:\\Users\\Selim Elbadri\\Dropbox\\KLEMS_productivity\\Input\"\n",
    "export_file_path = r\"C:\\Users\\Selim Elbadri\\Dropbox\\KLEMS_productivity\\Output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef23aabc",
   "metadata": {},
   "source": [
    "# 2. Functions & Industry Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "bb2b30ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute log-diff and drop original variable\n",
    "def dlog(df, var, group_col='indnum', time_col='yr', base_year=None):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values([group_col, time_col])\n",
    "    newvar = f'dlog_{var}'.replace(' ', '_')\n",
    "\n",
    "    #Compute log difference\n",
    "    df[newvar] = df.groupby(group_col)[var].transform(lambda x: np.log(x).diff())\n",
    "\n",
    "    #Force NaN for base_year or first available year in each group\n",
    "    if base_year is not None:\n",
    "        df.loc[df[time_col] == base_year, newvar] = np.nan\n",
    "    else:\n",
    "        min_years = df.groupby(group_col)[time_col].transform('min')\n",
    "        df.loc[df[time_col] == min_years, newvar] = np.nan\n",
    "\n",
    "    #Drop original variable\n",
    "    return df.drop(columns=[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "f46f5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Industry aggregations for 1947-1963\n",
    "aggregate_groups = {\n",
    "    2936: list(range(29, 37)),\n",
    "    3740: list(range(37, 41)),\n",
    "    4144: list(range(41, 45)),\n",
    "    4749: list(range(47, 50)),\n",
    "    5152: list(range(51, 53)),\n",
    "    5456: list(range(54, 57)),\n",
    "    5758: list(range(57, 59))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d58ed",
   "metadata": {},
   "source": [
    "# 3. Cleaning BEA-BLS Experimental Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd662e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify needed variables\n",
    "experimental_vars = ['yr','indnum','goqi.','iiqi.','vlcol.','vln.','vkit.','vksoft.','vkRD.',\n",
    "    'vkart.','vkoth.','qkit.','qks.','qkrd.','qka.','qko.','hrs','qlindexcol_merge.', 'qlindexn_merge.']\n",
    "\n",
    "#Extract datasheets from BEA-BLS Integrated Industry-Level Production Account (Eldridge et al., 2020)\n",
    "df_experimental_1947to1963 = pd.read_excel(os.path.join(import_file_path, 'industry-production-account-experimental.xlsx'), \n",
    "    sheet_name='1947-1963', skiprows=1, usecols=experimental_vars)\n",
    "df_experimental_1963to2016 = pd.read_excel(os.path.join(import_file_path, 'industry-production-account-experimental.xlsx'),\n",
    "    sheet_name='1963-2016', skiprows=1, usecols=experimental_vars)\n",
    "\n",
    "#Quantity indices to be log-differenced\n",
    "q_indices = ['goqi.','iiqi.','qkit.','qks.','qkrd.','qka.','qko.','qlindexcol_merge.','qlindexn_merge.','hrs']\n",
    "\n",
    "#Generate log-difference for quantity indices in both sheets\n",
    "for v in q_indices:\n",
    "    df_experimental_1947to1963 = dlog(df_experimental_1947to1963, v, base_year=1947)\n",
    "\n",
    "for v in q_indices:\n",
    "    df_experimental_1963to2016 = dlog(df_experimental_1963to2016, v, base_year=1963)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35644b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restrict BEA-BLS Experimental to 1997 (for nominal variables) and to 1998 (for growth variables)\n",
    "nom_var     = ['vlcol.','vln.', 'vkit.', 'vksoft.', 'vkRD.', 'vkart.', 'vkoth.']\n",
    "growth_var  = ['dlog_goqi.', 'dlog_iiqi.', 'dlog_qkit.', 'dlog_qks.', 'dlog_qkrd.', \n",
    "                   'dlog_qka.', 'dlog_qko.', 'dlog_qlindexcol_merge.', 'dlog_qlindexn_merge.', 'dlog_hrs']\n",
    "\n",
    "#Nominal variables stop after 1996\n",
    "df_experimental_1963to2016 = df_experimental_1963to2016.copy()\n",
    "for v in nom_var:\n",
    "    df_experimental_1963to2016.loc[(df_experimental_1963to2016['yr'] < 1963) | (df_experimental_1963to2016['yr'] > 1996),v] = np.nan\n",
    "\n",
    "#Growth variables stop after 1997\n",
    "for v in growth_var:\n",
    "    df_experimental_1963to2016.loc[(df_experimental_1963to2016['yr'] < 1963) | (df_experimental_1963to2016['yr'] > 1997),v] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca19b6d",
   "metadata": {},
   "source": [
    "# 4. Cleaning WK2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb78704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify needed variables\n",
    "klems_vars = ['year', 'industry', 'gross output', 'capital', 'labor', 'intermediate']\n",
    "\n",
    "#Extract the required datasheets from US KLEMS, March 2017 (Jorgenson et al., 2017)\n",
    "df_klems = pd.read_excel(os.path.join(import_file_path, 'usa_wk_mar_2017.xlsx'), sheet_name='KLEMdata', skiprows=1, usecols=klems_vars)\n",
    "\n",
    "#Rename panel identifiers to be consistent with df_experimental\n",
    "df_klems.rename(columns={'industry': 'indnum','year': 'yr'}, inplace=True)\n",
    "\n",
    "#Rename variables to be consistent with KLEMS literature\n",
    "df_klems.rename(columns={'gross output': 'GO','capital': 'CAP','labor': 'LAB','intermediate': 'II'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For consistency with other datasets, consolidate federal government and state & local government from 2 industries each to 1 industry each\n",
    "federal_inds          = [62, 63]\n",
    "state_local_inds      = [64, 65]\n",
    "\n",
    "#Sum nominal variables for indnum 62/63\n",
    "federal               = df_klems[df_klems['indnum'].isin(federal_inds)].groupby('yr', as_index=False)[['GO', 'CAP', 'LAB', 'II']].sum()\n",
    "\n",
    "#Sum nominal variables for indnum 64/65\n",
    "state_local           = df_klems[df_klems['indnum'].isin(state_local_inds)].groupby('yr', as_index=False)[['GO', 'CAP', 'LAB', 'II']].sum()\n",
    "\n",
    "federal['indnum']     = 62           #Consolidated Federal government indnum = 62\n",
    "state_local['indnum'] = 63           #Consolidated state & local indnum = 63\n",
    "\n",
    "#Remove the original rows and append new rows\n",
    "df_klems              = df_klems[~df_klems['indnum'].isin(federal_inds + state_local_inds)]\n",
    "df_klems              = pd.concat([df_klems, federal, state_local], ignore_index=True)\n",
    "\n",
    "#Sort by year and indnum\n",
    "df_klems              = df_klems.sort_values(['indnum','yr']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "742edf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build panel for broad industries starting from 1947-\n",
    "df_klems_1947to2014 = (\n",
    "    df_klems.assign(indnum=df_klems['indnum'].replace({i:new for new, olds in aggregate_groups.items() for i in olds}))\n",
    "    .groupby(['yr','indnum'], as_index=False)[['GO', 'CAP', 'LAB', 'II']].sum())\n",
    "\n",
    "#Build panel for finer industries starting 1963-\n",
    "df_klems_1963to2014 = df_klems.loc[df_klems['yr'] >= 1963].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522bb4a4",
   "metadata": {},
   "source": [
    "# 5. Cleaning BEA-BLS Capital Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0841da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of sheets to extract data from\n",
    "capital_sheets = [\n",
    "    'Capital_Art_Quantity','Capital_R&D_Quantity','Capital_IT_Quantity','Capital_Other_Quantity','Capital_Software_Quantity',\n",
    "    'Capital_Art Compensation', 'Capital_R&D Compensation','Capital_IT Compensation','Capital_Other Compensation','Capital_Software Compensation',\n",
    "    'Labor_Col_Quantity','Labor_NoCol_Quantity','Labor_Col Compensation','Labor_NoCol Compensation',\n",
    "    'Energy_Quantity','Materials_Quantity','Services_Quantity','Energy Compensation', \n",
    "    'Materials Compensation','Service Compensation','Gross Output', 'Gross Output_Quantity', 'Labor Hours_Quantity'\n",
    "]\n",
    "\n",
    "#Extract industry-level from BEA-BLS Integrated Industry-Level Production Account (Eldridge et al., 2025)\n",
    "long_data = []\n",
    "for sheet in capital_sheets:\n",
    "    df_tmp = pd.read_excel(os.path.join(import_file_path, 'industry-production-account-capital.xlsx'), sheet_name=sheet, header=1).dropna(how='all')\n",
    "    df_tmp = df_tmp.rename(columns={df_tmp.columns[0]: 'industry_description'})\n",
    "    df_tmp = df_tmp.melt(id_vars='industry_description', var_name='year', value_name=sheet)\n",
    "    long_data.append(df_tmp)\n",
    "df_capital_1997to2023 = reduce(lambda l, r: pd.merge(l, r, on=['industry_description','year'], how='outer'), long_data)\n",
    "df_capital_1997to2023 = df_capital_1997to2023.rename(columns={'year':'yr','industry_description':'Description'})\n",
    "\n",
    "#Create a sequential `indnum` for each unique Description with existing order\n",
    "order                           = df_capital_1997to2023['Description'].drop_duplicates().tolist()\n",
    "mapping                         = {desc: i+1 for i, desc in enumerate(order)}\n",
    "df_capital_1997to2023['indnum'] = df_capital_1997to2023['Description'].map(mapping).astype('Int64')\n",
    "df_capital_1997to2023['yr']     = pd.to_numeric(df_capital_1997to2023['yr'], errors='coerce')\n",
    "df_capital_1997to2023           = df_capital_1997to2023.drop(columns='Description')\n",
    "\n",
    "#Move panel identifiers first\n",
    "cols                            = ['indnum', 'yr'] + [c for c in df_capital_1997to2023.columns if c not in ['indnum', 'yr']]\n",
    "df_capital_1997to2023           = df_capital_1997to2023[cols]\n",
    "df_capital_1997to2023           = df_capital_1997to2023.sort_values(['indnum', 'yr']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5318366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename df_capital_1997to2023 variables to match df_experimental variable names\n",
    "experimental_dictionary = {\n",
    "    'Gross Output': 'go.','Capital_IT Compensation': 'vkit.','Capital_Software Compensation': 'vksoft.',\n",
    "    'Capital_R&D Compensation': 'vkRD.','Capital_Art Compensation': 'vkart.','Capital_Other Compensation': 'vkoth.',\n",
    "    'Labor_Col Compensation': 'vlcol.','Labor_NoCol Compensation': 'vln.','Gross Output_Quantity': 'goqi.',\n",
    "    'Capital_IT_Quantity': 'qkit.','Capital_Software_Quantity': 'qks.','Capital_R&D_Quantity': 'qkrd.',\n",
    "    'Capital_Art_Quantity': 'qka.','Capital_Other_Quantity': 'qko.','Labor_Col_Quantity': 'qlindexcol_merge.',\n",
    "    'Labor_NoCol_Quantity': 'qlindexn_merge.','Labor Hours_Quantity': 'hrs','Energy_Quantity': 'qien.',\n",
    "    'Materials_Quantity': 'qimt.','Services_Quantity': 'qisv.','Service Compensation': 'visv.',\n",
    "    'Materials Compensation': 'vimt.','Energy Compensation': 'vien.'\n",
    "}\n",
    "\n",
    "#Rename variables using experimental_dictionary\n",
    "rename_dict           = {k: v for k, v in experimental_dictionary.items() if k in df_capital_1997to2023.columns}\n",
    "df_capital_1997to2023 = df_capital_1997to2023.rename(columns=rename_dict)\n",
    "\n",
    "#Log difference the variables of interest\n",
    "q_indices             = ['goqi.','qkit.','qks.','qkrd.','qka.','qko.','qlindexcol_merge.','qlindexn_merge.','hrs','qien.','qimt.','qisv.']\n",
    "for v in q_indices:\n",
    "    if v in df_capital_1997to2023.columns:\n",
    "        df_capital_1997to2023 = dlog(df_capital_1997to2023, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc514a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use BEA-BLS Capital to compute nominal variables GO, II, LAB, CAP (needed for 2015-, both for broad industries and finer industries)\n",
    "df_capital_nominal = (df_capital_1997to2023[df_capital_1997to2023['yr'] >= 2015].copy())\n",
    "\n",
    "nominal_agg_map = {\n",
    "    'GO' : ['go.'],\n",
    "    'CAP': ['vkit.', 'vksoft.', 'vkRD.', 'vkart.', 'vkoth.'],\n",
    "    'LAB': ['vln.', 'vlcol.'],\n",
    "    'II' : ['visv.', 'vimt.', 'vien.']\n",
    "}\n",
    "for newvar, cols in nominal_agg_map.items():\n",
    "    cols_present               = [c for c in cols if c in df_capital_nominal.columns]\n",
    "    df_capital_nominal[newvar] = df_capital_nominal[cols_present].apply(pd.to_numeric, errors='coerce').sum(axis=1, min_count=1)\n",
    "\n",
    "#Keep nominal variables before 2015 missing for 1963 industries\n",
    "df_capital_nominal_start1963 = df_capital_nominal[['yr','indnum','GO','II','LAB','CAP']].reset_index(drop=True)\n",
    "\n",
    "#Aggregate some industries to match 1947-1963 \n",
    "df_capital_nominal_start1947 = (\n",
    "    df_capital_nominal_start1963.copy()\n",
    "    .assign(indnum=lambda d: d['indnum'].map({i:new for new, old in aggregate_groups.items() for i in old}).fillna(d['indnum']).astype('Int64'))\n",
    "    .groupby(['yr','indnum'], as_index=False)[['GO','II','LAB','CAP']].sum())\n",
    "df_capital_nominal_start1947 = df_capital_nominal_start1947.sort_values(by=['indnum', 'yr']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50044623",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Summary \n",
    "##In the cleaning stage, we have prepared 7 relevant dataframes:\n",
    "#df_experimental_1963to2016   : Quantity indices and compensation for factor components (1963-2016)\n",
    "#df_capital_1997to2023        : Quantity indices and compensation for factor components (1997-2023)\n",
    "#df_klems_1963to2014          : Nominal GO, II, CAP, LAB for 1963 industry aggregations (1963-2014)\n",
    "#df_capital_nominal_start1963 : Nominal GO, II, CAP, LAB for 1963 industry aggregations (2015-2023)\n",
    "\n",
    "#df_klems_1947to2014          : Nominal GO, II, CAP, LAB for 1947 industry aggregations (1947-2014)\n",
    "#df_capital_nominal_start1947 : Nominal GO, II, CAP, LAB for 1947 industry aggregations (2015-2023)\n",
    "#df_experimental_1947to1963   : Quantity indices and compensation for factor components (1947-1963)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981fbff2",
   "metadata": {},
   "source": [
    "# 6. Merging the Datasets for 1963-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "c54a68e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append df_klems_1963to2014 & df_capital_nominal_start1963 to create 1963-2023 GO, II, CAP, LAB panel\n",
    "df_nom_1963to2023 = pd.concat([df_klems_1963to2014, df_capital_nominal_start1963], ignore_index=True)\n",
    "df_nom_1963to2023 = df_nom_1963to2023.sort_values(by=['indnum', 'yr']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging quantity indices and compensation for factor components (1963-1996/97 & 1997/98-2023)  \n",
    "all_cols                   = list(set(df_experimental_1963to2016.columns).union(df_capital_1997to2023.columns))\n",
    "df_experimental_1963to2016 = df_experimental_1963to2016.reindex(columns=all_cols)\n",
    "df_capital_1997to2023      = df_capital_1997to2023.reindex(columns=all_cols)\n",
    "\n",
    "#Merge both datasets together\n",
    "df_extended = pd.merge(df_experimental_1963to2016,df_capital_1997to2023,on=[\"indnum\", \"yr\"], how=\"outer\", suffixes=(\"_exp\", \"_cap\"))\n",
    "\n",
    "#If same column appears twice, then coalesce\n",
    "for col in all_cols:\n",
    "    if col + \"_exp\" in df_extended and col + \"_cap\" in df_extended:\n",
    "        df_extended[col] = df_extended[col + \"_exp\"].combine_first(df_extended[col + \"_cap\"])\n",
    "        df_extended      = df_extended.drop(columns=[col + \"_exp\", col + \"_cap\"])\n",
    "\n",
    "#Sort by indnum-yr\n",
    "df_extended          = df_extended.sort_values(by=[\"indnum\", \"yr\"]).reset_index(drop=True)\n",
    "\n",
    "#Reorder variables after merging\n",
    "cols                 = df_extended.columns.tolist()\n",
    "merge_key            = [\"indnum\", \"yr\"]\n",
    "v_vars               = [c for c in cols if c.startswith(\"v\") and c not in merge_key]\n",
    "dlog_vars            = [c for c in cols if c.startswith(\"dlog_\")]\n",
    "interm_inp           = [\"dlog_iiqi.\", \"vien.\", \"vimt.\", \"visv.\",\"dlog_qisv.\", \"dlog_qimt.\", \"dlog_qien.\"]   #Keep II in the end because they are represented by different variables in both datasets\n",
    "               \n",
    "#Exclude interm_inp from v_vars and dlog_vars to avoid duplicates\n",
    "v_vars               = [c for c in v_vars if c not in interm_inp]\n",
    "dlog_vars            = [c for c in dlog_vars if c not in interm_inp]\n",
    "\n",
    "# Construct final order\n",
    "final_order          = merge_key + v_vars + dlog_vars + interm_inp\n",
    "df_qindices_63to2023 = df_extended[final_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "e07c9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge panel data with nominal values and panel data with quantity indices and compensation for factor components\n",
    "df_1963to2023 = pd.merge(df_nom_1963to2023,df_qindices_63to2023,on=['indnum', 'yr'],how='inner') \n",
    "df_1963to2023 = df_1963to2023.sort_values(by=['indnum', 'yr']).reset_index(drop=True)\n",
    "df_1963to2023 = df_1963to2023.sort_values(by=['indnum', 'yr']).reset_index(drop=True)\n",
    "other_cols    = [c for c in df_1963to2023.columns if c not in [\"indnum\", \"yr\"]]\n",
    "df_1963to2023 = df_1963to2023[[\"indnum\", \"yr\"] + other_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f92d0db",
   "metadata": {},
   "source": [
    "# 7. Merging the Datasets for 1947-1963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4715ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a panel dataset for nominal values 1947-1963 (merging KLEMS (1947-2014) and BEA-BLS Capital (2015-2023))\n",
    "all_cols                     = list(set(df_klems_1947to2014.columns).union(df_capital_nominal_start1947.columns))\n",
    "df_klems_1947to2014          = df_klems_1947to2014.reindex(columns=all_cols)\n",
    "df_capital_nominal_start1947 = df_capital_nominal_start1947.reindex(columns=all_cols)\n",
    "\n",
    "#Append both datasets\n",
    "df_nom_1947to2023            = pd.concat([df_klems_1947to2014, df_capital_nominal_start1947], ignore_index=True)\n",
    "\n",
    "#Sort by panel identifiers (indnum, yr)\n",
    "df_nom_1947to2023            = df_nom_1947to2023.sort_values(by=['indnum', 'yr']).reset_index(drop=True)\n",
    "other_cols                   = [c for c in df_nom_1947to2023.columns if c not in [\"indnum\", \"yr\"]]\n",
    "df_nom_1947to2023            = df_nom_1947to2023[[\"indnum\", \"yr\"] + other_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43154fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge df_nom_1947to2023 with df_experimental_1947to1963\n",
    "df_1947to2023   = pd.merge(df_nom_1947to2023,df_experimental_1947to1963,on=[\"indnum\", \"yr\"],how=\"outer\",suffixes=(\"_exp63\", \"_full\"))  # keeps all rows from both\n",
    "df_1947to2023   = df_1947to2023.sort_values(by=[\"indnum\", \"yr\"]).reset_index(drop=True)\n",
    "other_cols      = [c for c in df_1947to2023.columns if c not in [\"indnum\", \"yr\"]]\n",
    "df_1947to2023   = df_1947to2023[[\"indnum\", \"yr\"] + other_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36774399",
   "metadata": {},
   "source": [
    "# 8. Combine 1947-2023 and 1963-2023 Datasets and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a variable definition DataFrame (only Variable + Description)\n",
    "var_defs = pd.DataFrame({\n",
    "    \"Variable\": [\n",
    "        \"indnum\", \"yr\", \"GO\", \"CAP\", \"LAB\", \"II\", \"vkit.\",\n",
    "        \"vln.\", \"vkRD.\", \"vkoth.\", \"vlcol.\", \"vkart.\", \"vksoft.\", \"dlog_qko.\",\n",
    "        \"dlog_qkit.\", \"dlog_qlindexcol_merge.\", \"dlog_qkrd.\", \"dlog_goqi.\",\n",
    "        \"dlog_qlindexn_merge.\", \"dlog_qka.\", \"dlog_hrs\", \"dlog_qks.\", \"dlog_iiqi.\",\n",
    "        \"vien.\", \"vimt.\", \"visv.\", \"dlog_qisv.\", \"dlog_qimt.\", \"dlog_qien.\"\n",
    "    ],\n",
    "    \"Description\": [\n",
    "        \"Industry identifier\",                                   # indnum\n",
    "        \"Year\",                                                  # yr\n",
    "        \"Nominal Gross Output\",                                  # GO\n",
    "        \"Nominal Capital Compensation\",                          # CAP\n",
    "        \"Nominal Labor Compensation\",                            # LAB\n",
    "        \"Nominal Intermediate Input Compensation\",               # II\n",
    "        \"Nominal IT Equipment Capital Compensation\",             # vkit.\n",
    "        \"Nominal Non-college Labor Compensation\",                # vln.\n",
    "        \"Nominal R&D Capital Compensation\",                      # vkRD.\n",
    "        \"Nominal Other Capital Compensation\",                    # vkoth.\n",
    "        \"Nominal College Labor Compensation\",                    # vlcol.\n",
    "        \"Nominal Entertainment Originals Capital Compensation\",  # vkart.\n",
    "        \"Nominal Software Capital Compensation\",                 # vksoft.\n",
    "        \"Growth of Other Capital Quantity Index\",                # dlog_qko.\n",
    "        \"Growth of IT Equipment Capital Quantity Index\",         # dlog_qkit.\n",
    "        \"Growth of College Labor Quantity Index\",                # dlog_qlindexcol_merge.\n",
    "        \"Growth of R&D Capital Quantity Index\",                  # dlog_qkrd.\n",
    "        \"Growth of Gross Output Quantity Index\",                 # dlog_goqi.\n",
    "        \"Growth of Non-college Labor Quantity Index\",            # dlog_qlindexn_merge.\n",
    "        \"Growth of Entertainment Originals Quantity Index\",      # dlog_qka.\n",
    "        \"Growth of Total Hours\",                                 # dlog_hrs\n",
    "        \"Growth of Software Capital Quantity Index\",             # dlog_qks.\n",
    "        \"Growth of Intermediate Input Quantity Index\",           # dlog_iiqi.\n",
    "        \"Nominal Energy Intermediate Compensation\",              # vien.\n",
    "        \"Nominal Materials Intermediate Compensation\",           # vimt.\n",
    "        \"Nominal Services Intermediate Compensation\",            # visv.\n",
    "        \"Growth of Services Intermediate Input Quantity Index\",  # dlog_qisv.\n",
    "        \"Growth of Materials Intermediate Input Quantity Index\", # dlog_qimt.\n",
    "        \"Growth of Energy Intermediate Input Quantity Index\"     # dlog_qien.\n",
    "    ]\n",
    "})\n",
    "\n",
    "#Export Excel with multiple sheets\n",
    "os.makedirs(export_file_path, exist_ok=True)\n",
    "output_file = os.path.join(export_file_path, \"cleaned_data.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "    #Sheet 1 -- Legend\n",
    "    var_defs.to_excel(writer, sheet_name=\"Variable_Definitions\", index=False)\n",
    "    \n",
    "    #Sheets 2/3 -- Data\n",
    "    df_1963to2023.to_excel(writer, sheet_name=\"df_1963to2023\", index=False)\n",
    "    df_1947to2023.to_excel(writer, sheet_name=\"df_nom_1947to2023\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
