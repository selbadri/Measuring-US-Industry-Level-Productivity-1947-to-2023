{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeea91a2",
   "metadata": {},
   "source": [
    "## Measuring US Industry Level Productivity 1947-2023\n",
    "### [Juan Ignacio Vizcaino](https://www.jivizcaino.com/) and [Selim Elbadri](https://www.selimelbadri.com/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc79bbe",
   "metadata": {},
   "source": [
    "> We here combine data from US KLEMS, March 2017 Release, with BEA-BLS Integrated Industry-Level Production Account for 1947–2016, and BEA-BLS Integrated Industry-Level Production Account for 1997-2023 to produce industry-level measures of Gross Output (GO), Value Added (VA), Capital (CAP), Labor (LAB), and Intermediate Inputs (II), in Nominal and Real terms. We also provide Quantity Indices for GO, VA, CAP, LAB, and II, and utilize these indices to compute measures of Total Labor Productivity (LP) and Total Factor Productivity (TFP) for the corresponding time period, following the methodology in US KLEMS, April 2013 Release.\n",
    "See our [Gihub repo](https://github.com/selbadri/Measuring-US-Industry-Level-Productivity-1947-to-2023) for details on data processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270d5ffb",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf023ce",
   "metadata": {},
   "source": [
    "#### 1. Set up the Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "790b0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_file_path = rf\"..\\\\Input\"\n",
    "export_file_path = rf\"..\\\\Output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c8a2a",
   "metadata": {},
   "source": [
    "#### 2. Requirements: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1312efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b09a3",
   "metadata": {},
   "source": [
    "#### 3. Define Frequently Used Functions and Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd9bf3",
   "metadata": {},
   "source": [
    "Define some widely used functions (see docstring for details on what these functions do)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ea8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tornqvist_index(df, q_vars, v_vars, industry_column=None):\n",
    "    \"\"\"\n",
    "    This function calculatest a Tornqvist quantity index.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe containing quantity and value variables\n",
    "    q_vars : list\n",
    "        List of column names representing quantity variables to be aggregated\n",
    "    v_vars : list  \n",
    "        List of column names representing corresponding value variables\n",
    "        used for weighting. Must be same length as q_vars.\n",
    "    industry_column : str, optional\n",
    "        Column name for industry/group identifier. If provided, calculations\n",
    "        are performed separately for each industry group. If None, treats\n",
    "        entire dataset as single time series.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        Tornqvist quantity index values, normalized to 100 for the first\n",
    "        observation of each group (or first row if no grouping)\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The Tornqvist index formula used is:\n",
    "    ln(QI_t/QI_{t-1}) = Σ [0.5 * (w_i,t + w_i,t-1) * ln(q_i,t/q_i,t-1)]\n",
    "    \n",
    "    Where:\n",
    "    - QI_t is the quantity index at time t\n",
    "    - w_i,t is the value share of component i at time t (v_i,t / Σv_j,t)\n",
    "    - q_i,t is the quantity of component i at time t\n",
    "    \n",
    "    The index is initialized to 100 for the first period and cumulative\n",
    "    products are calculated to generate the full time series.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Calculate aggregate capital quantity index\n",
    "    >>> capital_qi = tornqvist_index(\n",
    "    ...     df, \n",
    "    ...     q_vars=['it_quantity', 'structures_quantity', 'equipment_quantity'],\n",
    "    ...     v_vars=['it_value', 'structures_value', 'equipment_value'],\n",
    "    ...     industry_column='industry_id'\n",
    "    ... )\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    total_v = df[v_vars].sum(axis=1)\n",
    "    for col in v_vars:\n",
    "        df[f'w_{col}'] = df[col] / total_v\n",
    "        \n",
    "    log_index_sum = 0\n",
    "    for q_var, v_var in zip(q_vars, v_vars):\n",
    "        w_var = f'w_{v_var}'\n",
    "        \n",
    "        if industry_column is not None:\n",
    "            log_change = np.log(df[q_var] / df.groupby(industry_column)[q_var].shift(1))\n",
    "            avg_weight = 0.5 * (df[w_var] + df.groupby(industry_column)[w_var].shift(1))\n",
    "        else:\n",
    "            log_change = np.log(df[q_var] / df[q_var].shift(1))\n",
    "            avg_weight = 0.5 * (df[w_var] + df[w_var].shift(1))\n",
    "\n",
    "        log_index_sum += avg_weight * log_change\n",
    "\n",
    "    q_growth_rate = np.exp(log_index_sum)\n",
    "\n",
    "    if industry_column is not None:\n",
    "        q_growth_rate.loc[df.groupby(industry_column).head(1).index] = 100\n",
    "        qi = q_growth_rate.groupby(df[industry_column]).cumprod()\n",
    "    else:\n",
    "        q_growth_rate.iloc[0] = 100\n",
    "        qi = q_growth_rate.cumprod()\n",
    "\n",
    "    return qi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(df, variable, year, industry_column):\n",
    "    \"\"\"Normalize variable to base year = 100 by industry.\"\"\"\n",
    "    base_values = df[df['year'] == year].set_index(industry_column)[variable]\n",
    "    normaliser = df[industry_column].map(base_values)\n",
    "    df[variable] = (df[variable] / normaliser) * 100\n",
    "    return df[variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "86d67123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(obj):\n",
    "    \"\"\"\n",
    "    Standardize names by replacing spaces with underscores and converting to lowercase.\n",
    "    This function is used for making column names consistent across different data sources.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obj : pd.DataFrame, list, or str\n",
    "        Object to clean\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Same type as input with standardized naming\n",
    "    \"\"\"\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        obj.columns = [col.replace(' ', '_').lower() for col in obj.columns]\n",
    "        return obj\n",
    "    elif isinstance(obj, list):\n",
    "        return [s.replace(' ', '_').lower() for s in obj]\n",
    "    elif isinstance(obj, str):\n",
    "        return obj.replace(' ', '_').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_industries(df):\n",
    "    \"\"\"\n",
    "    Create industry aggregates by combining individual industries into larger sectoral groups.\n",
    "    \n",
    "    This function is used to produce consistent industry aggregates from 1947-2023, given that the\n",
    "    BEA-BLS Industry Production Account Experimental file has aggregated data for industries 29-36,\n",
    "    37-40, 41-44, 47-49, 51-52, 54-56, and 57-58.\n",
    "    \n",
    "    The function creates aggregate industry groups (e.g., combining industries 29-36 into group 2936) for 1947-2023 \n",
    "    and computes appropriate Tornqvist quantity indices that maintain economic consistency.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe with MultiIndex ['year', 'industry_id'] containing individual\n",
    "        industry data with quantity indices and value added measures.\n",
    "        Required columns: qi_variables (quantity indices) and 'VA' (value added)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Original dataframe with additional rows for aggregate industries, each containing\n",
    "        appropriately calculated Tornqvist quantity indices for the combined sectors.\n",
    "        MultiIndex structure ['year', 'industry_id'] is preserved.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The function operates by:\n",
    "    1. Creating industry groups according to aggregate_groups mapping (see list below)\n",
    "    2. For each group and each quantity index variable:\n",
    "       - Extracting component industry data (quantities and values)\n",
    "       - Applying Tornqvist aggregation formula using individual industry weights\n",
    "       - Assigning new aggregate industry code to results\n",
    "    3. Concatenating aggregate results with original individual industry data\n",
    "    \n",
    "    The Tornqvist aggregation ensures that the aggregate indices properly reflect\n",
    "    the relative economic importance of component industries through value-based weighting.\n",
    "    \n",
    "    Dependencies\n",
    "    ------------\n",
    "    - Requires global variables: qi_variables, aggregate_groups\n",
    "    - Uses tornqvist_index() function for proper economic aggregation\n",
    "    - Assumes df contains 'VA' (Value Added) column for weighting\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    Typical usage in productivity analysis pipeline:\n",
    "    >>> # After calculating individual industry quantity indices\n",
    "    >>> df_with_aggregates = aggregate_industries(df_individual)\n",
    "    >>> # Result contains both individual industries (1, 2, 3, ...) \n",
    "    >>> # and aggregates (2936, 3740, 4144, ...)\n",
    "    \"\"\"\n",
    "    aggregate_dict = {}\n",
    "    df = df.reset_index()\n",
    "    for qi in qi_variables:\n",
    "        for agg_code, industries in aggregate_groups.items():\n",
    "            data_slice = df[df['industry_id'].isin(industries)].copy()\n",
    "\n",
    "            q_vars = []\n",
    "            v_vars = []\n",
    "\n",
    "            for industry in industries:\n",
    "                q = f'{industry}_{qi}'\n",
    "                v = f'{industry}_va'\n",
    "\n",
    "                services_index = df[df['industry_id'] == industry][['year', qi]].rename(columns={qi: q})\n",
    "                va = df[df['industry_id'] == industry][['year', 'VA']].rename(columns={'VA': v})\n",
    "            \n",
    "                data_slice = data_slice.merge(services_index, on='year', how='left')\n",
    "                data_slice = data_slice.merge(va, on='year', how='left')\n",
    "            \n",
    "                q_vars.append(q)\n",
    "                v_vars.append(v)\n",
    "\n",
    "            sum_cols = ['VA']\n",
    "            data_slice[sum_cols] = data_slice.groupby('year')[sum_cols].transform('sum')\n",
    "            data_slice = data_slice.drop_duplicates(subset='year')\n",
    "\n",
    "            data_slice[qi] = tornqvist_index(data_slice, q_vars=q_vars, v_vars=v_vars, industry_column='industry_id')\n",
    "            data_slice['industry_id'] = agg_code\n",
    "\n",
    "            if agg_code not in aggregate_dict:\n",
    "                aggregate_dict[agg_code] = data_slice[['year', 'industry_id'] + [qi] + sum_cols]\n",
    "            else:\n",
    "                aggregate_dict[agg_code] = aggregate_dict[agg_code].merge(data_slice[['year', 'industry_id', qi]], on=['year', 'industry_id'], how='left')\n",
    "\n",
    "    aggregate_df = pd.concat(aggregate_dict.values(), ignore_index=True)\n",
    "\n",
    "    df = pd.concat([df, aggregate_df], ignore_index=True).set_index(['year', 'industry_id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain(df_1, df_2, year):\n",
    "    \"\"\"\n",
    "    Chain together two time series datasets with overlapping periods using index linking.\n",
    "    \n",
    "    This function is used for creating consistent long-term economic time series \n",
    "    when combining data from different sources or periods. It ensures continuity by\n",
    "    scaling the second dataset to match the level of the first dataset at the \n",
    "    overlapping year, maintaining growth rates while eliminating level discontinuities.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_1 : pandas.DataFrame\n",
    "        First (earlier) dataset with MultiIndex ['year', 'industry_id'].\n",
    "        Contains quantity index variables that serve as the reference level.\n",
    "    df_2 : pandas.DataFrame\n",
    "        Second (later) dataset with MultiIndex ['year', 'industry_id'].\n",
    "        Will be scaled to match df_1 levels at the linking year.\n",
    "    year : int\n",
    "        Overlapping year used for linking the two datasets. This year's values\n",
    "        from df_1 provide the scaling factors for df_2.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Combined dataset with MultiIndex ['year', 'industry_id'] containing\n",
    "        the chained time series. df_1 data (excluding linking year) plus\n",
    "        df_2 data scaled to maintain continuity.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The chaining process:\n",
    "    1. Extracts scaling factors from df_1 at the linking year\n",
    "    2. Applies these factors to all df_2 observations to maintain relative levels\n",
    "    3. Removes the linking year from df_1 to avoid duplication\n",
    "    4. Combines the datasets preserving chronological order\n",
    "    \n",
    "    The scaling formula for each quantity index (qi) is:\n",
    "    df_2_scaled[qi] = df_2[qi] * (df_1[qi, linking_year] / 100)\n",
    "    \n",
    "    This preserves growth rates in df_2 while ensuring level consistency with df_1.\n",
    "    \n",
    "    Dependencies\n",
    "    ------------\n",
    "    - Requires global variable: qi_variables (list of quantity index column names)\n",
    "    - Both datasets must have matching industry_id values for proper scaling\n",
    "    - Missing scaling factors are filled with 100 (no adjustment)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    Typical usage in productivity analysis:\n",
    "    >>> # Chain 1947-1996 data with 1997-2023 data using 1997 as link year\n",
    "    >>> combined_data = chain(early_period_df, later_period_df, 1997)\n",
    "    >>> # Result: consistent time series from 1947-2023\n",
    "    \"\"\"\n",
    "    df_1 = df_1.reset_index()\n",
    "    df_2 = df_2.reset_index()\n",
    "\n",
    "    df_2_scaled = df_2.copy()\n",
    "\n",
    "    for qi in qi_variables:\n",
    "        scalers = f'{qi}_scalers'\n",
    "\n",
    "        df_1_year = df_1[df_1['year'] == year][['industry_id', qi]].rename(columns={qi: scalers})\n",
    "\n",
    "        df_2_scaled = df_2_scaled.merge(df_1_year, on='industry_id', how='left')\n",
    "        df_2_scaled[scalers] = df_2_scaled[scalers].fillna(100)\n",
    "        df_2_scaled[qi] *= df_2_scaled[scalers]\n",
    "        df_2_scaled[qi] = df_2_scaled[qi] / 100\n",
    "        df_2_scaled = df_2_scaled.drop(columns=scalers)\n",
    "\n",
    "    df_1 = df_1[df_1['year'] != year]\n",
    "\n",
    "    df_new = pd.concat([df_1, df_2_scaled], ignore_index=True)\n",
    "    df_new = df_new.set_index(['year', 'industry_id']).sort_values(by=['industry_id', 'year'])\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_values(df, variable, year):\n",
    "    \"\"\"\n",
    "    Convert nominal values to real (constant dollar) values using implicit price deflator.\n",
    "    \n",
    "    This function implements the standard economic method for converting nominal time series \n",
    "    into real values by extracting implicit price indices and deflating current values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe containing nominal values and corresponding quantity indices.\n",
    "        Must include columns: 'year', 'industry_id', variable, and f'{variable}_QI'\n",
    "    variable : str\n",
    "        Name of the nominal variable to convert (e.g., 'GO', 'CAP', 'LAB', 'II').\n",
    "        Must have a corresponding quantity index column f'{variable}_QI'\n",
    "    year : int\n",
    "        Base year for the constant dollar calculation. Real values will be expressed\n",
    "        in this year's dollars (e.g., 2009 for \"2009 constant dollars\")\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        Real (constant dollar) values for the specified variable, rounded to 4 decimals.\n",
    "        Series name will be f'REAL_{variable}' (e.g., 'REAL_GO')\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The conversion process follows these steps:\n",
    "    \n",
    "    1. Create value index:           V_index(t) = V(t) / V(base_year) × 100\n",
    "    2. Extract implicit price index: P_index(t) = V_index(t) / Q_index(t)  \n",
    "    3. Calculate real values:        REAL_V(t)  = V(t) / P_index(t)\n",
    "    \n",
    "    Where:\n",
    "    - V(t)       = nominal value at time t\n",
    "    - Q_index(t) = quantity index at time t  \n",
    "    - P_index(t) = implicit price index at time t\n",
    "    \n",
    "    This method ensures that real values reflect only quantity changes, with price\n",
    "    effects removed through the implicit deflation process.\n",
    "    \n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    Convert nominal gross output to 2009 constant dollars:\n",
    "    >>> real_go = constant_values(df, 'GO', 2009)\n",
    "    >>> # Result: REAL_GO series in 2009 constant dollars\n",
    "    \n",
    "    Convert nominal capital to 1997 constant dollars:  \n",
    "    >>> real_cap = constant_values(df, 'CAP', 1997)\n",
    "    >>> # Result: REAL_CAP series in 1997 constant dollars\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    values_year = {}\n",
    "    df_year = df[df['year'] == year].set_index('industry_id')\n",
    "    values_year = df_year[variable].to_dict()\n",
    "    df[f'{variable}_{year}'] = df['industry_id'].map(values_year)\n",
    "    df[f'{variable}_value_index'] = df[variable] / df[f'{variable}_{year}']\n",
    "    df[f'{variable}_value_index'] *= 100\n",
    "    df[f'{variable}_price_index'] = df[f'{variable}_value_index'] / df[f'{variable}_QI']\n",
    "    df[f'REAL_{variable}'] = df[variable] / df[f'{variable}_price_index']\n",
    "    df[f'REAL_{variable}'] = df[f'REAL_{variable}'].round(4)\n",
    "    return df[f'REAL_{variable}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90935562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_index(df, index_name, variable):\n",
    "    \"\"\"\n",
    "    Reconstruct level indices from cumulative log differences (growth rates).\n",
    "    \n",
    "    This function converts log difference series (growth rates) back into index levels that \n",
    "    can be normalized and compared across time periods. It is used to produce chained quantity\n",
    "    indices for when we have data on for overlapping periosds from different sources.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe containing log difference variables by industry.\n",
    "        Must include 'industry_id' column and f'delta_ln_{variable}' column.\n",
    "    index_name : str\n",
    "        Name for the recovered index variable (e.g., 'TFP_VA', 'LP_GO', 'VA_QI').\n",
    "        This becomes the column name for the output index.\n",
    "    variable : str\n",
    "        Base name of the log difference variable to recover from.\n",
    "        Function expects column f'delta_ln_{variable}' to exist in df.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        Recovered index series normalized to 100 for base period, with name=index_name.\n",
    "        Index values represent cumulative changes from the first observation.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Mathematical Process:\n",
    "    1. Cumulative sum: ln(Index_t) = Σ(Δln(Index_s)) for s = 1 to t\n",
    "    2. Exponentiation: Index_t     = exp(ln(Index_t))  \n",
    "    3. Normalization:  Index_t     = Index_t × 100\n",
    "    \n",
    "    Where Δln(Index_t) represents the log difference (growth rate) at time t.\n",
    "    \n",
    "    The cumulative sum is performed within each industry group, ensuring that\n",
    "    each industry's index starts from its own baseline period.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    Recover Total Factor Productivity index from growth rates:\n",
    "    >>> tfp_index = recover_index(df, 'TFP_VA', 'TFP_VA')\n",
    "    >>> # Creates index from delta_ln_TFP_VA growth rates\n",
    "    \n",
    "    Recover Value Added quantity index:\n",
    "    >>> va_qi = recover_index(df, 'VA_QI', 'VA_QI')  \n",
    "    >>> # Creates index from delta_ln_VA_QI growth rates\n",
    "    \"\"\"\n",
    "    \n",
    "    df['ln_' + variable] = df.groupby('industry_id')['delta_ln_' + variable].cumsum().fillna(0)\n",
    "    df[index_name] = np.exp(df['ln_' + variable])\n",
    "    df[index_name] *= 100\n",
    "    return df[index_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag(df, variable):\n",
    "    \"\"\"\n",
    "    Create lagged (previous period) values of a variable by industry group.\n",
    "    \n",
    "    It creates one-period lags within each industry group, ensuring that lagged values \n",
    "    don't bleed across different industries in the panel data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe containing the variable to lag. Must include 'industry_id' column\n",
    "        for proper grouping and should be sorted by time within each industry.\n",
    "    variable : str\n",
    "        Name of the column to create lagged values for. The lagged column will be named\n",
    "        f'{variable}_lag' (e.g., 'VA/GO' becomes 'VA/GO_lag').\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        Lagged values of the specified variable, with NaN for the first observation\n",
    "        of each industry group (no previous period available).\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    Create lagged value-added share for Tornqvist calculations:\n",
    "    >>> va_go_lag = lag(df, 'VA/GO')\n",
    "    >>> # Used in: avg_share = 0.5 * (df['VA/GO'] + va_go_lag)\n",
    "    \n",
    "    Create lagged labor share:\n",
    "    >>> lab_va_lag = lag(df, 'LAB/VA') \n",
    "    >>> # Used in TFP calculations for proper factor weighting\n",
    "    \"\"\"\n",
    "    df[f'{variable}_lag'] = df.groupby('industry_id')[variable].transform(lambda x: x.shift(1))\n",
    "    return df[f'{variable}_lag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7db026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(df, variable):\n",
    "    \"\"\"\n",
    "    Calculate first differences (period-over-period changes) of a variable by industry group.\n",
    "    This function computes simple arithmetic differences between consecutive periods\n",
    "    within each industry.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe containing the variable to difference. Must include 'industry_id' \n",
    "        column for proper grouping and should be sorted by time within each industry.\n",
    "    variable : str\n",
    "        Name of the column to calculate differences for. The difference column will be \n",
    "        named f'delta_{variable}' (e.g., 'ln_REAL_GO' becomes 'delta_ln_REAL_GO').\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        First differences of the specified variable, with NaN for the first observation\n",
    "        of each industry group (no previous period for comparison).\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Mathematical Operation:\n",
    "    delta_X(t) = X(t) - X(t-1)\n",
    "    \n",
    "    When applied to logarithmic variables:\n",
    "    delta_ln_X(t) = ln(X(t)) - ln(X(t-1)) = ln(X(t)/X(t-1))\n",
    "    \n",
    "    This represents the continuous growth rate, which is approximately equal to\n",
    "    the percentage change for small changes.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    Calculate log growth rate of real gross output:\n",
    "    >>> go_growth = delta(df, 'ln_REAL_GO')\n",
    "    >>> # Result: delta_ln_REAL_GO = ln(GO_t) - ln(GO_{t-1})\n",
    "    \n",
    "    Calculate change in labor share:\n",
    "    >>> share_change = delta(df, 'LAB/VA') \n",
    "    >>> # Result: delta_LAB/VA = (LAB/VA)_t - (LAB/VA)_{t-1}\n",
    "    \"\"\"\n",
    "    df[f'delta_{variable}'] = df.groupby('industry_id')[variable].transform(lambda x: x - x.shift(1))\n",
    "    return df[f'delta_{variable}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03795217",
   "metadata": {},
   "source": [
    "Define two widely used lists. The first list *aggregate_groups* is useful to aggregate industries at the same level as the BEA-BLS Industry Production Account Experimental for the period of 1947-1963.\n",
    "The second set of lists define variable groupings that are useful for computations later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_groups = {\n",
    "    2936: list(range(29, 37)),\n",
    "    3740: list(range(37, 41)),\n",
    "    4144: list(range(41, 45)),\n",
    "    4749: list(range(47, 50)),\n",
    "    5152: list(range(51, 53)),\n",
    "    5456: list(range(54, 57)),\n",
    "    5758: list(range(57, 59))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_variables               = ['GO', 'CAP', 'LAB', 'II']\n",
    "constant_variables           = ['REAL_GO', 'REAL_CAP', 'REAL_LAB', 'REAL_II']\n",
    "qi_variables                 = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI']\n",
    "productivity_index_variables = ['TFP_GO', 'TFP_VA', 'LP_GO', 'LP_VA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6f127",
   "metadata": {},
   "source": [
    "# 3. 1947 to 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d36af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "\n",
    "required_columns = ['yr', 'indnum', 'go.', 'goqi.', 'ii.', 'iiqi.', 'vlcol.', 'vln.', 'vkit.', 'vksoft.', 'vkRD.', 'vkart.', 'vkoth.', 'qlindexcol_merge.', 'qlindexn_merge.', 'qkit.', 'qks.', 'qkrd.', 'qka.', 'qko.', 'hrs']\n",
    "\n",
    "data_1 = pd.read_excel(os.path.join(import_file_path,'industry-production-account-experimental.xlsx'), sheet_name='1947-1963', skiprows=1, usecols=required_columns)\n",
    "data_2 = pd.read_excel(os.path.join(import_file_path,'industry-production-account-experimental.xlsx'), sheet_name='1963-2016', skiprows=1, usecols=required_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9018fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantity indices\n",
    "\n",
    "data_1 = data_1.reset_index()\n",
    "data_2 = data_2.reset_index()\n",
    "\n",
    "q_vars_dict_1 = {\n",
    "    'GO': ['goqi.'],\n",
    "    'CAP': ['qkit.', 'qks.', 'qkrd.', 'qka.', 'qko.'],\n",
    "    'LAB': ['qlindexcol_merge.', 'qlindexn_merge.'],\n",
    "    'II': ['iiqi.']}\n",
    "\n",
    "v_vars_dict_1 = {\n",
    "    'GO': ['go.'],\n",
    "    'CAP':  ['vkit.', 'vksoft.', 'vkRD.', 'vkart.', 'vkoth.'],\n",
    "    'LAB': ['vlcol.', 'vln.'],\n",
    "    'II': ['ii.']}\n",
    "\n",
    "for df in [data_1, data_2]:\n",
    "    for variable in core_variables:\n",
    "        q_vars = q_vars_dict_1[variable]\n",
    "        v_vars = v_vars_dict_1[variable]\n",
    "        df[f'{variable}_QI'] = tornqvist_index(df, q_vars, v_vars, industry_column='indnum')\n",
    "\n",
    "data_1['VA'] = data_1['go.'] - data_1['ii.']\n",
    "data_2['VA'] = data_2['go.'] - data_2['ii.']\n",
    "\n",
    "data_1.reset_index(inplace=True)\n",
    "data_2.reset_index(inplace=True)\n",
    "data_1 = data_1[qi_variables + ['hrs', 'VA', 'indnum', 'yr']]\n",
    "data_2 = data_2[qi_variables + ['hrs', 'VA', 'indnum', 'yr']]\n",
    "data_1 = data_1.rename(columns={'hrs': 'hours', 'indnum': 'industry_id', 'yr': 'year'})\n",
    "data_2 = data_2.rename(columns={'hrs': 'hours', 'indnum': 'industry_id', 'yr': 'year'})\n",
    "data_1 = data_1.set_index(['year', 'industry_id'])\n",
    "data_2 = data_2.set_index(['year', 'industry_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30bd8b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate industries\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI', 'hours']\n",
    "\n",
    "data_2 = aggregate_industries(data_2)\n",
    "data_2 = data_2.drop(columns=['VA'])\n",
    "data_1 = data_1.drop(columns=['VA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65d8662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.reset_index(inplace=True)\n",
    "data_2.reset_index(inplace=True)\n",
    "\n",
    "data_1['hours'] = normalise(data_1, 'hours', year=1947, industry_column='industry_id')\n",
    "data_2['hours'] = normalise(data_2, 'hours', year=1963, industry_column='industry_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1851030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain together data_1 (early period) and data_2 (late period)\n",
    "\n",
    "df_qi_47_to_16 = chain(data_1, data_2, 1963)\n",
    "\n",
    "df_47_to_16_hours = df_qi_47_to_16['hours'].copy()\n",
    "\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03621f3d",
   "metadata": {},
   "source": [
    "# 4. BEA (1997 to 2023) and KLEMS2017 (1947 to 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15127835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing and processing BEA data\n",
    "\n",
    "cap_qty_list = ['Capital_Art_Quantity', 'Capital_R&D_Quantity', 'Capital_IT_Quantity', 'Capital_Other_Quantity', 'Capital_Software_Quantity']\n",
    "cap_comp_list = ['Capital_Art Compensation', 'Capital_R&D Compensation', 'Capital_IT Compensation', 'Capital_Other Compensation', 'Capital_Software Compensation']\n",
    "\n",
    "lab_qty_list = ['Labor_Col_Quantity', 'Labor_NoCol_Quantity']\n",
    "lab_comp_list = ['Labor_Col Compensation', 'Labor_NoCol Compensation']\n",
    "\n",
    "ii_qty_list = ['Energy_Quantity', 'Materials_Quantity', 'Services_Quantity']\n",
    "ii_comp_list = ['Energy Compensation', 'Materials Compensation', 'Service Compensation']\n",
    "\n",
    "relevant_sheets = cap_qty_list + cap_comp_list + lab_qty_list + lab_comp_list + ii_qty_list + ii_comp_list + ['Value Added'] + ['VA_Quantity'] + ['Gross Output'] + ['Gross Output_Quantity'] + ['Labor Hours_Quantity']\n",
    "\n",
    "long_data = []\n",
    "\n",
    "for sheet in relevant_sheets:\n",
    "    df = pd.read_excel(os.path.join(import_file_path, 'industry-production-account-capital.xlsx'), sheet_name=sheet, header=[1])\n",
    "    df = df.dropna(how='all')\n",
    "    df.rename(columns={df.columns[0]: 'industry'}, inplace=True) \n",
    "    df_long = df.melt(id_vars='industry', var_name='Year', value_name=sheet)\n",
    "    long_data.append(df_long)\n",
    "\n",
    "df = reduce(lambda left, right: pd.merge(left, right, on=['industry', 'Year'], how='outer'), long_data)\n",
    "\n",
    "industry_order = long_data[0]['industry'].drop_duplicates().tolist()\n",
    "industry_id_map = {industry: i+1 for i, industry in enumerate(industry_order)}\n",
    "df['industry_id'] = df['industry'].map(industry_id_map)\n",
    "\n",
    "df = clean(df)\n",
    "cap_qty_list = clean(cap_qty_list)\n",
    "cap_comp_list = clean(cap_comp_list)\n",
    "lab_qty_list = clean(lab_qty_list)\n",
    "lab_comp_list = clean(lab_comp_list)\n",
    "ii_qty_list = clean(ii_qty_list)\n",
    "ii_comp_list = clean(ii_comp_list)\n",
    "\n",
    "df['year'] = df['year'].astype(int)\n",
    "df = df.set_index(['industry_id', 'year']).sort_index(level=['industry_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08e88357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing and processing KLEMS data\n",
    "\n",
    "df_klems = pd.read_excel(os.path.join(import_file_path, 'usa_wk_mar_2017.xlsx'), sheet_name='KLEMdata', header=[1])\n",
    "df_klems = df_klems[['year', 'industry', 'gross output', 'capital', 'labor', 'intermediate']]\n",
    "df_klems = df_klems.rename(columns={'gross output': 'GO', 'capital': 'CAP', 'labor': 'LAB', 'intermediate': 'II', 'industry': 'industry_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad47feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal values\n",
    "\n",
    "df = df.rename(columns={'gross_output': 'GO', 'value_added': 'VA', 'labor_hours_quantity': 'hours'})\n",
    "df['LAB'] = df[lab_comp_list].sum(axis=1)\n",
    "df['CAP'] = df[cap_comp_list].sum(axis=1)\n",
    "df['II'] = df[ii_comp_list].sum(axis=1)\n",
    "\n",
    "df_post_2014 = df.copy()\n",
    "df_post_2014 = df_post_2014.reset_index()\n",
    "df_post_2014 = df_post_2014[core_variables + ['industry_id', 'year', 'hours']]\n",
    "df_post_2014 = df_post_2014[df_post_2014['year'] > 2014]\n",
    "\n",
    "df_klems_62_63 = df_klems['industry_id'].isin([62, 63])\n",
    "df_62 = df_klems[df_klems_62_63].groupby('year').sum()\n",
    "df_62['industry_id'] = 62\n",
    "df_62 = df_62.reset_index()\n",
    "\n",
    "df_klems_64_65 = df_klems['industry_id'].isin([64, 65])\n",
    "df_63 = df_klems[df_klems_64_65].groupby('year').sum()\n",
    "df_63['industry_id'] = 63\n",
    "df_63 = df_63.reset_index()\n",
    "\n",
    "df_klems = df_klems[~df_klems['industry_id'].isin([62, 63, 64, 65])]\n",
    "df_klems = pd.concat([df_klems, df_62, df_63], ignore_index=True)\n",
    "\n",
    "df_nominal_47_to_23 = pd.concat([df_post_2014, df_klems], ignore_index=True)\n",
    "\n",
    "# nominal values in aggregate industries\n",
    "\n",
    "aggregate_dict = {}\n",
    "\n",
    "for agg_code, industries in aggregate_groups.items():\n",
    "    data_slice = df_nominal_47_to_23[df_nominal_47_to_23['industry_id'].isin(industries)].copy()\n",
    "    data_slice[core_variables] = data_slice.groupby('year')[core_variables].transform('sum')\n",
    "    data_slice = data_slice.drop_duplicates(subset='year')\n",
    "    data_slice['industry_id'] = agg_code\n",
    "    aggregate_dict[agg_code] = data_slice[['year', 'industry_id'] + core_variables]\n",
    "\n",
    "df_nominal_47_to_23 = pd.concat([df_nominal_47_to_23] + list(aggregate_dict.values()), ignore_index=True).set_index(['year', 'industry_id']).sort_index(level=['industry_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b0341cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nacho\\AppData\\Local\\Temp\\ipykernel_13764\\4183792477.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qi_97_to_23['hours'] = normalise(df, 'hours', year=1997, industry_column='industry_id')\n"
     ]
    }
   ],
   "source": [
    "# quantity indices\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "q_vars_dict_2 = {\n",
    "    'GO': ['gross_output_quantity'],\n",
    "    'CAP': cap_qty_list,\n",
    "    'LAB': lab_qty_list,\n",
    "    'II': ii_qty_list}\n",
    "\n",
    "v_vars_dict_2 = {\n",
    "    'GO': ['GO'],\n",
    "    'CAP': cap_comp_list,\n",
    "    'LAB': lab_comp_list,\n",
    "    'II': ii_comp_list}\n",
    "\n",
    "for variable in core_variables:\n",
    "    q_vars = q_vars_dict_2[variable]\n",
    "    v_vars = v_vars_dict_2[variable]\n",
    "    df[f'{variable}_QI'] = tornqvist_index(df, q_vars, v_vars, industry_column='industry_id')\n",
    "\n",
    "df['year'] = df['year'].astype(int)\n",
    "\n",
    "df_qi_97_to_23 = df[qi_variables + ['year', 'industry_id', 'VA', 'hours']] \n",
    "df_qi_97_to_23['hours'] = normalise(df, 'hours', year=1997, industry_column='industry_id')\n",
    "df_qi_97_to_23 = df_qi_97_to_23.set_index(['year', 'industry_id']).sort_index(level=['industry_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66343798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate industries\n",
    "\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI', 'hours']\n",
    "\n",
    "df_qi_97_to_23 = aggregate_industries(df_qi_97_to_23)\n",
    "\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI']\n",
    "\n",
    "df_qi_97_to_23 = df_qi_97_to_23.drop(columns=['VA'])\n",
    "\n",
    "df_97_to_23_hours = df_qi_97_to_23['hours'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0511be",
   "metadata": {},
   "source": [
    "# 5. Chaining 1947-2016 with 1997-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "252d29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_47_to_96_hours = df_47_to_16_hours[df_47_to_16_hours.index.get_level_values('year').astype(int) <= 1997]\n",
    "qi_variables = ['hours']\n",
    "df_47_to_23_hours = chain(df_47_to_96_hours, df_97_to_23_hours, 1997)\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8305e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qi_47_to_96 = df_qi_47_to_16[df_qi_47_to_16.index.get_level_values('year').astype(int) <= 1997]\n",
    "\n",
    "df_qi_47_to_23 = chain(df_qi_47_to_96, df_qi_97_to_23, 1997)\n",
    "\n",
    "df_qi_47_to_23 = df_qi_47_to_23.reset_index()\n",
    "\n",
    "df_qi_47_to_23['year'] = df_qi_47_to_23['year'].astype(int)\n",
    "\n",
    "for qi in qi_variables:\n",
    "   df_qi_47_to_23[qi] = normalise(df_qi_47_to_23, qi, year=2009, industry_column='industry_id')\n",
    "\n",
    "df_qi_47_to_23 = df_qi_47_to_23.set_index(['year', 'industry_id']).sort_index(level=['industry_id'])\n",
    "\n",
    "df_47_to_23 = pd.merge(df_nominal_47_to_23[core_variables], df_qi_47_to_23[qi_variables],  left_index=True, right_index=True, how='inner').round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d106c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_47_to_23 = pd.merge(df_47_to_23, df_47_to_23_hours, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d43293",
   "metadata": {},
   "source": [
    "# 6. Calculating constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18643efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant values\n",
    "\n",
    "df_47_to_23 = df_47_to_23.reset_index()\n",
    "\n",
    "for variable in core_variables:\n",
    "    df_47_to_23[f'REAL_{variable}'] = constant_values(df_47_to_23, variable, 2009)\n",
    "\n",
    "df_47_to_23 = df_47_to_23.set_index(['year', 'industry_id']).sort_index(level=['industry_id'])\n",
    "\n",
    "df_47_to_23 = df_47_to_23[core_variables + constant_variables + qi_variables + ['hours']]\n",
    "\n",
    "df = df_47_to_23.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112da32",
   "metadata": {},
   "source": [
    "# 7. Building productivity indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24831958",
   "metadata": {},
   "source": [
    "### 7.1 Nominal Value Added\n",
    "$$\n",
    "P_{V A}(t) Q_{V A}(t) = P_Y (t) Q_Y (t) - P_{II} (t) Q_{II} (t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "285ef3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VA'] = df['GO'] - df['II']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a4cbc",
   "metadata": {},
   "source": [
    "Nominal Value Added share of Gross Output:\n",
    "$$\n",
    "\\nu_{V A}(t) = \\frac{P_{V A}(t) Q_{V A}(t)}{P_Y (t) Q_Y (t)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc613dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VA/GO'] = df['VA'] / df['GO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0047b87",
   "metadata": {},
   "source": [
    "### 7.2 Value Added index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe21eff",
   "metadata": {},
   "source": [
    "To compute a value added quantity index, we start from the definition of a Tornqvist Quantity Index for total output $Y$\n",
    "\n",
    "$$\n",
    "\\Delta \\ln Q_Y (t) = \\bar{\\nu}_{V A} (t) \\Delta \\ln Q_{VA}(t)   + \\bar{\\nu}_{II} (t) \\Delta \\ln Q_{II} (t)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\Delta \\ln X(t) = \\ln X(t) - \\ln X(t - 1)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\bar{\\nu}_X(t) = 0.5 \\times \\left( \\frac{P_X(t) Q_X(t)}{P_Y (t) Q_Y (t)} + \\frac{P_X(t - 1) Q_X(t - 1)}{P_Y (t - 1) Q_Y (t - 1)} \\right).\n",
    "$$\n",
    "\n",
    "In the formula above $\\bar{\\nu}_{VA}(t)$ and $\\bar{\\nu}_{II}(t)$ represent the Tornqvist weights for $(VA)$ and intermediate inputs $(II)$, respectively.\n",
    "\n",
    "Re arranging terms, we get:\n",
    "\n",
    "$$\n",
    "\\Delta \\ln Q_{VA}(t) = \\frac{\\Delta \\ln Q_Y (t) - \\bar{\\nu}_{II} (t) \\Delta \\ln Q_{II} (t)}{\\bar{\\nu}_{V A} (t)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b7582",
   "metadata": {},
   "source": [
    "#### 7.2.1 Compute log differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a61a6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ln_REAL_GO'] = np.log(df['REAL_GO'])\n",
    "df['ln_REAL_II'] = np.log(df['REAL_II'])\n",
    "\n",
    "df['delta_ln_REAL_GO'] = delta(df, 'ln_REAL_GO')\n",
    "df['delta_ln_REAL_II'] = delta(df, 'ln_REAL_II')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601dae9",
   "metadata": {},
   "source": [
    "#### 7.2.2 Compute the Tornqvist Output Weights\n",
    "\n",
    "$$\n",
    "\\bar{\\nu}_X(t) = 0.5 \\times \\left( \\frac{P_X(t) Q_X(t)}{P_Y (t) Q_Y (t)} + \\frac{P_X(t - 1) Q_X(t - 1)}{P_Y (t - 1) Q_Y (t - 1)} \\right)\n",
    "$$\n",
    "\n",
    "where X is either nominal VA or nominal II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "110f81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['II/GO'] = df['II'] / df['GO']\n",
    "\n",
    "df['VA/GO_lag'] = lag(df, 'VA/GO')\n",
    "df['II/GO_lag'] = lag(df, 'II/GO')\n",
    "\n",
    "df['VA_tornqvist_GO_share'] = 0.5 * (df['VA/GO'] + df['VA/GO_lag'])\n",
    "df['II_tornqvist_GO_share'] = 0.5 * (df['II/GO'] + df['II/GO_lag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab08361",
   "metadata": {},
   "source": [
    "#### 7.2.3 Compute the log change of the Value Added quantity index\n",
    "\n",
    "$$\n",
    "\\Delta \\ln Q_{VA}(t) = \\frac{\\Delta \\ln Q_Y (t) - \\bar{\\nu}_{II} (t) \\Delta \\ln Q_{II} (t)}{\\bar{\\nu}_{V A} (t)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fefc0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_ln_VA_QI'] = ((df['delta_ln_REAL_GO'] - (df['II_tornqvist_GO_share']*df['delta_ln_REAL_II']))/df['VA_tornqvist_GO_share'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86461156",
   "metadata": {},
   "source": [
    "### 7.3 Labour Productivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be29c4ae",
   "metadata": {},
   "source": [
    "For now, our measure of labor quantity is real compensation of employees. It follows that:\n",
    "LP_VA:\n",
    "$$\n",
    "\\Delta \\ln LP(t) = \\Delta \\ln Q_{VA}(t) - \\Delta \\ln Q_L(t)\n",
    "$$\n",
    "LP_GO:\n",
    "$$\n",
    "\\Delta \\ln LP(t) = \\Delta \\ln Q_{GO}(t) - \\Delta \\ln Q_L(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "777c3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ln_REAL_LAB'] = np.log(df['REAL_LAB'])\n",
    "df['delta_ln_REAL_LAB'] = delta(df, 'ln_REAL_LAB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b0920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ln_hours'] = np.log(df['hours'])\n",
    "df['delta_ln_hours'] = delta(df, 'ln_hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17660705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_ln_LP_VA'] = (df['delta_ln_VA_QI'] - df['delta_ln_hours'])\n",
    "df['delta_ln_LP_GO'] = (df['delta_ln_REAL_GO'] - df['delta_ln_hours'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fee178",
   "metadata": {},
   "source": [
    "### 7.4 Total Factor Productivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803eee6",
   "metadata": {},
   "source": [
    "Assuming that VA is produced by combining capital and labor services and TFP via a Tornqvist Index, we can back out log change in TFP using\n",
    "$$\n",
    "\\Delta \\ln TFP(t) = \\Delta \\ln Q_{VA}(t) - \\bar{\\psi}_L(t) \\Delta \\ln Q_L(t) - \\bar{\\psi}_K(t) \\Delta \\ln Q_K(t),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\bar{\\psi}_X(t) = 0.5 \\times \\left( \\frac{P_X(t) Q_X(t)}{P_{VA}(t) Q_{VA}(t)} + \\frac{P_X(t-1) Q_X(t-1)}{P_{VA}(t-1) Q_{VA}(t-1)} \\right)\n",
    "$$\n",
    "\n",
    "and X is either nominal LAB (L) or nominal CAP (K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67873f",
   "metadata": {},
   "source": [
    "#### 7.4.1 Tornqvist VA and GO share\n",
    "\n",
    "$$\n",
    "\\bar{\\psi}_X(t) = 0.5 \\times \\left( \\frac{P_X(t) Q_X(t)}{P_{VA}(t) Q_{VA}(t)} + \\frac{P_X(t-1) Q_X(t-1)}{P_{VA}(t-1) Q_{VA}(t-1)} \\right)\n",
    "$$\n",
    "\n",
    "where X is either nominal $LAB (L)$ or nominal $CAP (K)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb057518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LAB/VA'] = df['LAB'] / df['VA']\n",
    "df['CAP/VA'] = df['CAP'] / df['VA']\n",
    "df['LAB/VA_lag'] = lag(df, 'LAB/VA')\n",
    "df['CAP/VA_lag'] = lag(df, 'CAP/VA')\n",
    "df['L_tornqvist_VA_share'] = 0.5 * (df['LAB/VA'] + df['LAB/VA_lag'])\n",
    "df['CAP_tornqvist_VA_share'] = 0.5 * (df['CAP/VA'] + df['CAP/VA_lag'])\n",
    "\n",
    "df['LAB/GO'] = df['LAB'] / df['GO']\n",
    "df['CAP/GO'] = df['CAP'] / df['GO']\n",
    "df['LAB/GO_lag'] = lag(df, 'LAB/GO')\n",
    "df['CAP/GO_lag'] = lag(df, 'CAP/GO')\n",
    "df['L_tornqvist_GO_share'] = 0.5 * (df['LAB/GO'] + df['LAB/GO_lag'])\n",
    "df['CAP_tornqvist_GO_share'] = 0.5 * (df['CAP/GO'] + df['CAP/GO_lag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf21b91",
   "metadata": {},
   "source": [
    "#### 7.4.2 Real capital; logged and log difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "016a4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ln_REAL_CAP'] = np.log(df['REAL_CAP'])\n",
    "df['delta_ln_REAL_CAP'] = delta(df, 'ln_REAL_CAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d571a6a7",
   "metadata": {},
   "source": [
    "#### 7.4.3 TFP growth rate\n",
    "TFP_VA:\n",
    "$$\n",
    "\\Delta \\ln TFP(t) = \\Delta \\ln Q_{VA}(t) - \\bar{\\psi}_L(t) \\Delta \\ln Q_L(t) - \\bar{\\psi}_K(t) \\Delta \\ln Q_K(t)\n",
    "$$\n",
    "\n",
    "TFP_GO:\n",
    "$$\n",
    "\\Delta \\ln TFP(t) = \\Delta \\ln Q_{GO}(t) - \\bar{\\psi}_L(t) \\Delta \\ln Q_L(t) - \\bar{\\psi}_K(t) \\Delta \\ln Q_K(t) - \\bar{\\psi}_{II}(t) \\Delta \\ln Q_{II}(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a40d7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_ln_TFP_VA'] = (df['delta_ln_VA_QI'] - (df['L_tornqvist_VA_share']*df['delta_ln_REAL_LAB']) - (df['CAP_tornqvist_VA_share']*df['delta_ln_REAL_CAP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ea5fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_ln_TFP_GO'] = (df['delta_ln_REAL_GO'] - (df)['L_tornqvist_GO_share']*df['delta_ln_REAL_LAB'] - (df['CAP_tornqvist_GO_share']*df['delta_ln_REAL_CAP']) - (df['II_tornqvist_GO_share']*df['delta_ln_REAL_II']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aedaa3",
   "metadata": {},
   "source": [
    "### 7.5 Recover the TFP, LP and VA indexes, then normalise to 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62366c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover index function \n",
    "\n",
    "def recover_index(df, index_name):\n",
    "    df['ln_' + index_name] = df.groupby('industry_id')['delta_ln_' + index_name].cumsum().fillna(0)\n",
    "    df[index_name] = np.exp(df['ln_' + index_name])\n",
    "    df[index_name] *= 100\n",
    "    return df[index_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78fdb918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "\n",
    "for variable in productivity_index_variables:\n",
    "    df[variable] = recover_index(df, variable)\n",
    "    df[variable] = normalise(df, variable, year=2009, industry_column='industry_id')\n",
    "df['VA_QI'] = recover_index(df, 'VA_QI')\n",
    "df['VA_QI'] = normalise(df, 'VA_QI', year=2009, industry_column='industry_id')\n",
    "\n",
    "df = df.set_index(['year', 'industry_id']).sort_index(level=['industry_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc66b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[core_variables + ['VA'] + constant_variables + qi_variables + ['VA_QI'] + productivity_index_variables].round(4)\n",
    "df_complete = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80703810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('year', 'industry_id')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "GO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CAP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LAB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "II",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "REAL_GO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "REAL_CAP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "REAL_LAB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "REAL_II",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GO_QI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CAP_QI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LAB_QI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "II_QI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VA_QI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TFP_GO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TFP_VA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LP_GO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LP_VA",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "48f24bbe-845e-413a-b29c-e240ee2ef285",
       "rows": [
        [
         "(1947, 1)",
         "31299.23",
         "9744.228",
         "10039.002",
         "11516.0",
         "19783.23",
         "85420.7366",
         "58072.4257",
         "175614.4448",
         "71655.418",
         "28.0331",
         "91.8022",
         "350.6423",
         "37.443",
         "18.6973",
         "34.2724",
         "9.9743",
         "4.7605",
         "3.1752"
        ],
        [
         "(1948, 1)",
         "35560.695",
         "11602.553",
         "11443.142",
         "12515.0",
         "23045.695",
         "93240.3033",
         "62451.0323",
         "169739.8335",
         "71305.9727",
         "30.5993",
         "98.724",
         "338.9127",
         "37.2604",
         "21.4984",
         "37.0196",
         "11.2514",
         "5.2976",
         "3.722"
        ],
        [
         "(1949, 1)",
         "29746.566",
         "6988.223",
         "11310.343",
         "11448.0",
         "18298.566",
         "90564.3063",
         "62630.1163",
         "170840.071",
         "70636.9362",
         "29.7211",
         "99.0071",
         "341.1095",
         "36.9108",
         "20.6429",
         "35.9716",
         "10.7512",
         "5.2764",
         "3.6647"
        ],
        [
         "(1950, 1)",
         "31972.906",
         "9193.447",
         "10284.459",
         "12495.0",
         "19477.906",
         "95692.0309",
         "63096.6455",
         "158602.6833",
         "74804.0615",
         "31.4039",
         "99.7446",
         "316.6756",
         "39.0883",
         "21.7807",
         "38.0812",
         "11.7999",
         "5.8552",
         "4.061"
        ],
        [
         "(1951, 1)",
         "37255.438",
         "11954.302",
         "10551.134",
         "14750.0",
         "22505.438",
         "94865.6469",
         "67334.6291",
         "150626.2118",
         "79642.3284",
         "31.1327",
         "106.4441",
         "300.7493",
         "41.6165",
         "20.6164",
         "36.6797",
         "11.0925",
         "6.0988",
         "4.0387"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GO</th>\n",
       "      <th>CAP</th>\n",
       "      <th>LAB</th>\n",
       "      <th>II</th>\n",
       "      <th>VA</th>\n",
       "      <th>REAL_GO</th>\n",
       "      <th>REAL_CAP</th>\n",
       "      <th>REAL_LAB</th>\n",
       "      <th>REAL_II</th>\n",
       "      <th>GO_QI</th>\n",
       "      <th>CAP_QI</th>\n",
       "      <th>LAB_QI</th>\n",
       "      <th>II_QI</th>\n",
       "      <th>VA_QI</th>\n",
       "      <th>TFP_GO</th>\n",
       "      <th>TFP_VA</th>\n",
       "      <th>LP_GO</th>\n",
       "      <th>LP_VA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>industry_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <th>1</th>\n",
       "      <td>31299.230</td>\n",
       "      <td>9744.228</td>\n",
       "      <td>10039.002</td>\n",
       "      <td>11516.0</td>\n",
       "      <td>19783.230</td>\n",
       "      <td>85420.7366</td>\n",
       "      <td>58072.4257</td>\n",
       "      <td>175614.4448</td>\n",
       "      <td>71655.4180</td>\n",
       "      <td>28.0331</td>\n",
       "      <td>91.8022</td>\n",
       "      <td>350.6423</td>\n",
       "      <td>37.4430</td>\n",
       "      <td>18.6973</td>\n",
       "      <td>34.2724</td>\n",
       "      <td>9.9743</td>\n",
       "      <td>4.7605</td>\n",
       "      <td>3.1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <th>1</th>\n",
       "      <td>35560.695</td>\n",
       "      <td>11602.553</td>\n",
       "      <td>11443.142</td>\n",
       "      <td>12515.0</td>\n",
       "      <td>23045.695</td>\n",
       "      <td>93240.3033</td>\n",
       "      <td>62451.0323</td>\n",
       "      <td>169739.8335</td>\n",
       "      <td>71305.9727</td>\n",
       "      <td>30.5993</td>\n",
       "      <td>98.7240</td>\n",
       "      <td>338.9127</td>\n",
       "      <td>37.2604</td>\n",
       "      <td>21.4984</td>\n",
       "      <td>37.0196</td>\n",
       "      <td>11.2514</td>\n",
       "      <td>5.2976</td>\n",
       "      <td>3.7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <th>1</th>\n",
       "      <td>29746.566</td>\n",
       "      <td>6988.223</td>\n",
       "      <td>11310.343</td>\n",
       "      <td>11448.0</td>\n",
       "      <td>18298.566</td>\n",
       "      <td>90564.3063</td>\n",
       "      <td>62630.1163</td>\n",
       "      <td>170840.0710</td>\n",
       "      <td>70636.9362</td>\n",
       "      <td>29.7211</td>\n",
       "      <td>99.0071</td>\n",
       "      <td>341.1095</td>\n",
       "      <td>36.9108</td>\n",
       "      <td>20.6429</td>\n",
       "      <td>35.9716</td>\n",
       "      <td>10.7512</td>\n",
       "      <td>5.2764</td>\n",
       "      <td>3.6647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <th>1</th>\n",
       "      <td>31972.906</td>\n",
       "      <td>9193.447</td>\n",
       "      <td>10284.459</td>\n",
       "      <td>12495.0</td>\n",
       "      <td>19477.906</td>\n",
       "      <td>95692.0309</td>\n",
       "      <td>63096.6455</td>\n",
       "      <td>158602.6833</td>\n",
       "      <td>74804.0615</td>\n",
       "      <td>31.4039</td>\n",
       "      <td>99.7446</td>\n",
       "      <td>316.6756</td>\n",
       "      <td>39.0883</td>\n",
       "      <td>21.7807</td>\n",
       "      <td>38.0812</td>\n",
       "      <td>11.7999</td>\n",
       "      <td>5.8552</td>\n",
       "      <td>4.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <th>1</th>\n",
       "      <td>37255.438</td>\n",
       "      <td>11954.302</td>\n",
       "      <td>10551.134</td>\n",
       "      <td>14750.0</td>\n",
       "      <td>22505.438</td>\n",
       "      <td>94865.6469</td>\n",
       "      <td>67334.6291</td>\n",
       "      <td>150626.2118</td>\n",
       "      <td>79642.3284</td>\n",
       "      <td>31.1327</td>\n",
       "      <td>106.4441</td>\n",
       "      <td>300.7493</td>\n",
       "      <td>41.6165</td>\n",
       "      <td>20.6164</td>\n",
       "      <td>36.6797</td>\n",
       "      <td>11.0925</td>\n",
       "      <td>6.0988</td>\n",
       "      <td>4.0387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         GO        CAP        LAB       II         VA  \\\n",
       "year industry_id                                                        \n",
       "1947 1            31299.230   9744.228  10039.002  11516.0  19783.230   \n",
       "1948 1            35560.695  11602.553  11443.142  12515.0  23045.695   \n",
       "1949 1            29746.566   6988.223  11310.343  11448.0  18298.566   \n",
       "1950 1            31972.906   9193.447  10284.459  12495.0  19477.906   \n",
       "1951 1            37255.438  11954.302  10551.134  14750.0  22505.438   \n",
       "\n",
       "                     REAL_GO    REAL_CAP     REAL_LAB     REAL_II    GO_QI  \\\n",
       "year industry_id                                                             \n",
       "1947 1            85420.7366  58072.4257  175614.4448  71655.4180  28.0331   \n",
       "1948 1            93240.3033  62451.0323  169739.8335  71305.9727  30.5993   \n",
       "1949 1            90564.3063  62630.1163  170840.0710  70636.9362  29.7211   \n",
       "1950 1            95692.0309  63096.6455  158602.6833  74804.0615  31.4039   \n",
       "1951 1            94865.6469  67334.6291  150626.2118  79642.3284  31.1327   \n",
       "\n",
       "                    CAP_QI    LAB_QI    II_QI    VA_QI   TFP_GO   TFP_VA  \\\n",
       "year industry_id                                                           \n",
       "1947 1             91.8022  350.6423  37.4430  18.6973  34.2724   9.9743   \n",
       "1948 1             98.7240  338.9127  37.2604  21.4984  37.0196  11.2514   \n",
       "1949 1             99.0071  341.1095  36.9108  20.6429  35.9716  10.7512   \n",
       "1950 1             99.7446  316.6756  39.0883  21.7807  38.0812  11.7999   \n",
       "1951 1            106.4441  300.7493  41.6165  20.6164  36.6797  11.0925   \n",
       "\n",
       "                   LP_GO   LP_VA  \n",
       "year industry_id                  \n",
       "1947 1            4.7605  3.1752  \n",
       "1948 1            5.2976  3.7220  \n",
       "1949 1            5.2764  3.6647  \n",
       "1950 1            5.8552  4.0610  \n",
       "1951 1            6.0988  4.0387  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4248d9a",
   "metadata": {},
   "source": [
    "# 8. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24a837be",
   "metadata": {},
   "outputs": [],
   "source": [
    "industries_info = (\n",
    "    pd.DataFrame(list(industry_id_map.items()), columns=['industry_name', 'industry_id'])\n",
    "    .sort_values('industry_id')\n",
    "    .reset_index(drop=True))\n",
    "\n",
    "variables_dictionary = {\n",
    "    '*': 'Note: variables with * are normalised to 2009 = 100',\n",
    "    'GO': 'Nominal Gross Output',\n",
    "    'CAP': 'Nominal Capital',\n",
    "    'LAB': 'Nominal Labor',\n",
    "    'II': 'Nominal Intermediate Inputs',\n",
    "    'VA': 'Nominal Value Added',\n",
    "    'REAL_GO*': 'Real Gross Output',\n",
    "    'REAL_CAP*': 'Real Capital',\n",
    "    'REAL_LAB*': 'Real Labor',\n",
    "    'REAL_II*': 'Real Intermediate Inputs',\n",
    "    'GO_QI*': 'Gross Output Quantity Index',\n",
    "    'CAP_QI*': 'Capital Quantity Index',\n",
    "    'LAB_QI*': 'Labor Quantity Index',\n",
    "    'II_QI*': 'Intermediate Inputs Quantity Index',\n",
    "    'VA_QI*': 'Value Added Quantity Index',\n",
    "    'TFP_GO*': 'Total Factor Productivity Index (GO)',\n",
    "    'TFP_VA*': 'Total Factor Productivity Index (VA)',\n",
    "    'LP_GO*': 'Labor Productivity Index (GO)',\n",
    "    'LP_VA*': 'Labor Productivity Index (VA)',\n",
    "}\n",
    "\n",
    "variables_info = pd.DataFrame(\n",
    "    list(variables_dictionary.items()), \n",
    "    columns=['variable_name', 'variable_description'])\n",
    "\n",
    "aggregate_industries_dictionary = {\n",
    "    'Period': '1947-2023',\n",
    "    '2936': 'Industries 29-36',\n",
    "    '3740': 'Industries 37-40',\n",
    "    '4144': 'Industries 41-44',\n",
    "    '4749': 'Industries 47-49',\n",
    "    '5152': 'Industries 51-52',\n",
    "    '5456': 'Industries 54-56',\n",
    "    '5758': 'Industries 57-58'\n",
    "}\n",
    "\n",
    "aggregate_industries_info = pd.DataFrame(\n",
    "    list(aggregate_industries_dictionary.items()),\n",
    "    columns=['industry_group', 'industry_ids']\n",
    ")\n",
    "\n",
    "file_path = os.path.join(export_file_path, \"EV_production_accounts_1947to2023.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    industries_info.to_excel(writer, sheet_name='Info', index=False, startrow=1, startcol=1)\n",
    "    aggregate_industries_info.to_excel(writer, sheet_name='Info', index=False, startrow=1, startcol=4)\n",
    "    variables_info.to_excel(writer, sheet_name='Info', index=False, startrow=1, startcol=7)\n",
    "    df_complete.to_excel(writer, sheet_name='Data', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
