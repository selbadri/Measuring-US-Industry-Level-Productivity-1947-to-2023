{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427c8a2a",
   "metadata": {},
   "source": [
    "# 1. Libraries and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1312efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_file_path = rf\"..\\\\Input\"\n",
    "export_file_path = rf\"..\\\\Output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b09a3",
   "metadata": {},
   "source": [
    "# 2. Functions and frequent lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "518ea8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tornqvist/quantity index function\n",
    "\n",
    "def tornqvist_index(df, q_vars, v_vars, industry_column=None):\n",
    "    df = df.copy()\n",
    "    total_v = df[v_vars].sum(axis=1)\n",
    "    for col in v_vars:\n",
    "        df[f'w_{col}'] = df[col] / total_v\n",
    "        \n",
    "    log_index_sum = 0\n",
    "    for q_var, v_var in zip(q_vars, v_vars):\n",
    "        w_var = f'w_{v_var}'\n",
    "        \n",
    "        if industry_column is not None:\n",
    "            log_change = np.log(df[q_var] / df.groupby(industry_column)[q_var].shift(1))\n",
    "            avg_weight = 0.5 * (df[w_var] + df.groupby(industry_column)[w_var].shift(1))\n",
    "        else:\n",
    "            log_change = np.log(df[q_var] / df[q_var].shift(1))\n",
    "            avg_weight = 0.5 * (df[w_var] + df[w_var].shift(1))\n",
    "\n",
    "        log_index_sum += avg_weight * log_change\n",
    "\n",
    "    q_growth_rate = np.exp(log_index_sum)\n",
    "\n",
    "    if industry_column is not None:\n",
    "        q_growth_rate.loc[df.groupby(industry_column).head(1).index] = 100\n",
    "        qi = q_growth_rate.groupby(df[industry_column]).cumprod()\n",
    "    else:\n",
    "        q_growth_rate.iloc[0] = 100\n",
    "        qi = q_growth_rate.cumprod()\n",
    "\n",
    "    return qi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5704161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise to a base year\n",
    "\n",
    "def normalise(df, variable, year, industry_column):\n",
    "    base_year_values = {} \n",
    "    normaliser = {}\n",
    "    df_year = df[df['year'] == year].set_index(industry_column)\n",
    "    base_year_values = df_year[variable].to_dict()\n",
    "    normaliser = df[industry_column].map(base_year_values)\n",
    "    df[variable] = ((df[variable] / normaliser) * 100)\n",
    "    return df[variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86d67123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean list or df by removing spaces and converting to lowercase\n",
    "\n",
    "def clean(obj):\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        obj.columns = [col.replace(' ', '_').lower() for col in obj.columns]\n",
    "        return obj\n",
    "    \n",
    "    elif isinstance(obj, list):\n",
    "        return [s.replace(' ', '_').lower() for s in obj]\n",
    "    \n",
    "    elif isinstance(obj, str):\n",
    "        return obj.replace(' ', '_').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3086817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of variable types\n",
    "\n",
    "core_variables = ['GO', 'CAP', 'LAB', 'II']\n",
    "\n",
    "constant_variables = ['REAL_GO', 'REAL_CAP', 'REAL_LAB', 'REAL_II']\n",
    "\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI']\n",
    "\n",
    "productivity_index_variables = ['TFP_GO', 'TFP_VA', 'LP_GO', 'LP_VA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b98a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate industries function\n",
    "\n",
    "aggregate_groups = {\n",
    "    2936: list(range(29, 37)),\n",
    "    3740: list(range(37, 41)),\n",
    "    4144: list(range(41, 45)),\n",
    "    4749: list(range(47, 50)),\n",
    "    5152: list(range(51, 53)),\n",
    "    5456: list(range(54, 57)),\n",
    "    5758: list(range(57, 59))}\n",
    "\n",
    "def aggregate_industries(df):\n",
    "    aggregate_dict = {}\n",
    "    df = df.reset_index()\n",
    "    for qi in qi_variables:\n",
    "        for agg_code, industries in aggregate_groups.items():\n",
    "            data_slice = df[df['industry_id'].isin(industries)].copy()\n",
    "\n",
    "            q_vars = []\n",
    "            v_vars = []\n",
    "\n",
    "            for industry in industries:\n",
    "                q = f'{industry}_{qi}'\n",
    "                v = f'{industry}_va'\n",
    "\n",
    "                services_index = df[df['industry_id'] == industry][['year', qi]].rename(columns={qi: q})\n",
    "                va = df[df['industry_id'] == industry][['year', 'VA']].rename(columns={'VA': v})\n",
    "            \n",
    "                data_slice = data_slice.merge(services_index, on='year', how='left')\n",
    "                data_slice = data_slice.merge(va, on='year', how='left')\n",
    "            \n",
    "                q_vars.append(q)\n",
    "                v_vars.append(v)\n",
    "\n",
    "            sum_cols = ['VA']\n",
    "            data_slice[sum_cols] = data_slice.groupby('year')[sum_cols].transform('sum')\n",
    "            data_slice = data_slice.drop_duplicates(subset='year')\n",
    "\n",
    "            data_slice[qi] = tornqvist_index(data_slice, q_vars=q_vars, v_vars=v_vars, industry_column='industry_id')\n",
    "            data_slice['industry_id'] = agg_code\n",
    "\n",
    "            if agg_code not in aggregate_dict:\n",
    "                aggregate_dict[agg_code] = data_slice[['year', 'industry_id'] + [qi] + sum_cols]\n",
    "            else:\n",
    "                aggregate_dict[agg_code] = aggregate_dict[agg_code].merge(data_slice[['year', 'industry_id', qi]], on=['year', 'industry_id'], how='left')\n",
    "\n",
    "    aggregate_df = pd.concat(aggregate_dict.values(), ignore_index=True)\n",
    "\n",
    "    df = pd.concat([df, aggregate_df], ignore_index=True).set_index(['year', 'industry_id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86e3150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain together two dataframes function \n",
    "\n",
    "def chain(df_1, df_2, year):\n",
    "    df_1 = df_1.reset_index()\n",
    "    df_2 = df_2.reset_index()\n",
    "\n",
    "    df_2_scaled = df_2.copy()\n",
    "\n",
    "    for qi in qi_variables:\n",
    "        scalers = f'{qi}_scalers'\n",
    "\n",
    "        df_1_year = df_1[df_1['year'] == year][['industry_id', qi]].rename(columns={qi: scalers})\n",
    "\n",
    "        df_2_scaled = df_2_scaled.merge(df_1_year, on='industry_id', how='left')\n",
    "        df_2_scaled[scalers] = df_2_scaled[scalers].fillna(100)\n",
    "        df_2_scaled[qi] *= df_2_scaled[scalers]\n",
    "        df_2_scaled[qi] = df_2_scaled[qi] / 100\n",
    "        df_2_scaled = df_2_scaled.drop(columns=scalers)\n",
    "\n",
    "    df_1 = df_1[df_1['year'] != year]\n",
    "\n",
    "    df_new = pd.concat([df_1, df_2_scaled], ignore_index=True)\n",
    "    df_new = df_new.set_index(['year', 'industry_id']).sort_values(by=['industry_id', 'year'])\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a83f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant values function \n",
    "\n",
    "def constant_values(df, variable, year):\n",
    "    df = df.copy()\n",
    "    values_year = {}\n",
    "    df_year = df[df['year'] == year].set_index('industry_id')\n",
    "    values_year = df_year[variable].to_dict()\n",
    "    df[f'{variable}_{year}'] = df['industry_id'].map(values_year)\n",
    "    df[f'{variable}_value_index'] = df[variable] / df[f'{variable}_{year}']\n",
    "    df[f'{variable}_value_index'] *= 100\n",
    "    df[f'{variable}_price_index'] = df[f'{variable}_value_index'] / df[f'{variable}_QI']\n",
    "    df[f'REAL_{variable}'] = df[variable] / df[f'{variable}_price_index']\n",
    "    df[f'REAL_{variable}'] = df[f'REAL_{variable}'].round(4)\n",
    "    return df[f'REAL_{variable}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90935562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover index function \n",
    "\n",
    "def recover_index(df, index_name, variable):\n",
    "    df['ln_' + variable] = df.groupby('industry_id')['delta_ln_' + variable].cumsum().fillna(0)\n",
    "    df[index_name] = np.exp(df['ln_' + variable])\n",
    "    df[index_name] *= 100\n",
    "    return df[index_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c273a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag \n",
    "\n",
    "def lag(df, variable):\n",
    "    df[f'{variable}_lag'] = df.groupby('industry_id')[variable].transform(lambda x: x.shift(1))\n",
    "    return df[f'{variable}_lag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f7db026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta\n",
    "\n",
    "def delta(df, variable):\n",
    "    df[f'delta_{variable}'] = df.groupby('industry_id')[variable].transform(lambda x: x - x.shift(1))\n",
    "    return df[f'delta_{variable}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6f127",
   "metadata": {},
   "source": [
    "# 3. 1947 to 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d36af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "\n",
    "required_columns = ['yr', 'indnum', 'go.', 'goqi.', 'ii.', 'iiqi.', 'vlcol.', 'vln.', 'vkit.', 'vksoft.', 'vkRD.', 'vkart.', 'vkoth.', 'qlindexcol_merge.', 'qlindexn_merge.', 'qkit.', 'qks.', 'qkrd.', 'qka.', 'qko.', 'hrs']\n",
    "\n",
    "data_1 = pd.read_excel(os.path.join(import_file_path,'industry_production_account_experimental.xlsx'), sheet_name='1947-1963', skiprows=1, usecols=required_columns)\n",
    "data_2 = pd.read_excel(os.path.join(import_file_path,'industry_production_account_experimental.xlsx'), sheet_name='1963-2016', skiprows=1, usecols=required_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9018fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantity indices\n",
    "\n",
    "data_1 = data_1.reset_index()\n",
    "data_2 = data_2.reset_index()\n",
    "\n",
    "q_vars_dict_1 = {\n",
    "    'GO': ['goqi.'],\n",
    "    'CAP': ['qkit.', 'qks.', 'qkrd.', 'qka.', 'qko.'],\n",
    "    'LAB': ['qlindexcol_merge.', 'qlindexn_merge.'],\n",
    "    'II': ['iiqi.']}\n",
    "\n",
    "v_vars_dict_1 = {\n",
    "    'GO': ['go.'],\n",
    "    'CAP':  ['vkit.', 'vksoft.', 'vkRD.', 'vkart.', 'vkoth.'],\n",
    "    'LAB': ['vlcol.', 'vln.'],\n",
    "    'II': ['ii.']}\n",
    "\n",
    "for df in [data_1, data_2]:\n",
    "    for variable in core_variables:\n",
    "        q_vars = q_vars_dict_1[variable]\n",
    "        v_vars = v_vars_dict_1[variable]\n",
    "        df[f'{variable}_QI'] = tornqvist_index(df, q_vars, v_vars, industry_column='indnum')\n",
    "\n",
    "data_1['VA'] = data_1['go.'] - data_1['ii.']\n",
    "data_2['VA'] = data_2['go.'] - data_2['ii.']\n",
    "\n",
    "data_1.reset_index(inplace=True)\n",
    "data_2.reset_index(inplace=True)\n",
    "data_1 = data_1[qi_variables + ['hrs', 'VA', 'indnum', 'yr']]\n",
    "data_2 = data_2[qi_variables + ['hrs', 'VA', 'indnum', 'yr']]\n",
    "data_1 = data_1.rename(columns={'hrs': 'hours', 'indnum': 'industry_id', 'yr': 'year'})\n",
    "data_2 = data_2.rename(columns={'hrs': 'hours', 'indnum': 'industry_id', 'yr': 'year'})\n",
    "data_1 = data_1.set_index(['year', 'industry_id'])\n",
    "data_2 = data_2.set_index(['year', 'industry_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30bd8b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate industries\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI', 'hours']\n",
    "\n",
    "data_2 = aggregate_industries(data_2)\n",
    "data_2 = data_2.drop(columns=['VA'])\n",
    "data_1 = data_1.drop(columns=['VA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65d8662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.reset_index(inplace=True)\n",
    "data_2.reset_index(inplace=True)\n",
    "\n",
    "data_1['hours'] = normalise(data_1, 'hours', year=1947, industry_column='industry_id')\n",
    "data_2['hours'] = normalise(data_2, 'hours', year=1963, industry_column='industry_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1851030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain together data_1 (early period) and data_2 (late period)\n",
    "\n",
    "df_qi_47_to_16 = chain(data_1, data_2, 1963)\n",
    "\n",
    "df_47_to_16_hours = df_qi_47_to_16['hours'].copy()\n",
    "\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03621f3d",
   "metadata": {},
   "source": [
    "# 4. BEA (1997 to 2023) and KLEMS2017 (1947 to 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15127835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing and processing BEA data\n",
    "\n",
    "cap_qty_list = ['Capital_Art_Quantity', 'Capital_R&D_Quantity', 'Capital_IT_Quantity', 'Capital_Other_Quantity', 'Capital_Software_Quantity']\n",
    "cap_comp_list = ['Capital_Art Compensation', 'Capital_R&D Compensation', 'Capital_IT Compensation', 'Capital_Other Compensation', 'Capital_Software Compensation']\n",
    "\n",
    "lab_qty_list = ['Labor_Col_Quantity', 'Labor_NoCol_Quantity']\n",
    "lab_comp_list = ['Labor_Col Compensation', 'Labor_NoCol Compensation']\n",
    "\n",
    "ii_qty_list = ['Energy_Quantity', 'Materials_Quantity', 'Services_Quantity']\n",
    "ii_comp_list = ['Energy Compensation', 'Materials Compensation', 'Service Compensation']\n",
    "\n",
    "relevant_sheets = cap_qty_list + cap_comp_list + lab_qty_list + lab_comp_list + ii_qty_list + ii_comp_list + ['Value Added'] + ['VA_Quantity'] + ['Gross Output'] + ['Gross Output_Quantity'] + ['Labor Hours_Quantity']\n",
    "\n",
    "long_data = []\n",
    "\n",
    "for sheet in relevant_sheets:\n",
    "    df = pd.read_excel(os.path.join(import_file_path, 'industry_production_account_capital.xlsx'), sheet_name=sheet, header=[1])\n",
    "    df = df.dropna(how='all')\n",
    "    df.rename(columns={df.columns[0]: 'industry'}, inplace=True) \n",
    "    df_long = df.melt(id_vars='industry', var_name='Year', value_name=sheet)\n",
    "    long_data.append(df_long)\n",
    "\n",
    "df = reduce(lambda left, right: pd.merge(left, right, on=['industry', 'Year'], how='outer'), long_data)\n",
    "\n",
    "industry_order = long_data[0]['industry'].drop_duplicates().tolist()\n",
    "industry_id_map = {industry: i+1 for i, industry in enumerate(industry_order)}\n",
    "df['industry_id'] = df['industry'].map(industry_id_map)\n",
    "\n",
    "df = clean(df)\n",
    "cap_qty_list = clean(cap_qty_list)\n",
    "cap_comp_list = clean(cap_comp_list)\n",
    "lab_qty_list = clean(lab_qty_list)\n",
    "lab_comp_list = clean(lab_comp_list)\n",
    "ii_qty_list = clean(ii_qty_list)\n",
    "ii_comp_list = clean(ii_comp_list)\n",
    "\n",
    "df['year'] = df['year'].astype(int)\n",
    "df = df.set_index(['industry_id', 'year']).sort_index(level=['industry_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08e88357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing and processing KLEMS data\n",
    "\n",
    "df_klems = pd.read_excel(os.path.join(import_file_path, 'usa_wk_mar_2017.xlsx'), sheet_name='KLEMdata', header=[1])\n",
    "df_klems = df_klems[['year', 'industry', 'gross output', 'capital', 'labor', 'intermediate']]\n",
    "df_klems = df_klems.rename(columns={'gross output': 'GO', 'capital': 'CAP', 'labor': 'LAB', 'intermediate': 'II', 'industry': 'industry_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad47feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal values\n",
    "\n",
    "df = df.rename(columns={'gross_output': 'GO', 'value_added': 'VA', 'labor_hours_quantity': 'hours'})\n",
    "df['LAB'] = df[lab_comp_list].sum(axis=1)\n",
    "df['CAP'] = df[cap_comp_list].sum(axis=1)\n",
    "df['II'] = df[ii_comp_list].sum(axis=1)\n",
    "\n",
    "df_post_2014 = df.copy()\n",
    "df_post_2014 = df_post_2014.reset_index()\n",
    "df_post_2014 = df_post_2014[core_variables + ['industry_id', 'year', 'hours']]\n",
    "df_post_2014 = df_post_2014[df_post_2014['year'] > 2014]\n",
    "\n",
    "df_klems_62_63 = df_klems['industry_id'].isin([62, 63])\n",
    "df_62 = df_klems[df_klems_62_63].groupby('year').sum()\n",
    "df_62['industry_id'] = 62\n",
    "df_62 = df_62.reset_index()\n",
    "\n",
    "df_klems_64_65 = df_klems['industry_id'].isin([64, 65])\n",
    "df_63 = df_klems[df_klems_64_65].groupby('year').sum()\n",
    "df_63['industry_id'] = 63\n",
    "df_63 = df_63.reset_index()\n",
    "\n",
    "df_klems = df_klems[~df_klems['industry_id'].isin([62, 63, 64, 65])]\n",
    "df_klems = pd.concat([df_klems, df_62, df_63], ignore_index=True)\n",
    "\n",
    "df_nominal_47_to_23 = pd.concat([df_post_2014, df_klems], ignore_index=True)\n",
    "\n",
    "# nominal values in aggregate industries\n",
    "\n",
    "aggregate_dict = {}\n",
    "\n",
    "for agg_code, industries in aggregate_groups.items():\n",
    "    data_slice = df_nominal_47_to_23[df_nominal_47_to_23['industry_id'].isin(industries)].copy()\n",
    "    data_slice[core_variables] = data_slice.groupby('year')[core_variables].transform('sum')\n",
    "    data_slice = data_slice.drop_duplicates(subset='year')\n",
    "    data_slice['industry_id'] = agg_code\n",
    "    aggregate_dict[agg_code] = data_slice[['year', 'industry_id'] + core_variables]\n",
    "\n",
    "df_nominal_47_to_23 = pd.concat([df_nominal_47_to_23] + list(aggregate_dict.values()), ignore_index=True).set_index(['year', 'industry_id']).sort_index(level=['industry_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b0341cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\4183792477.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qi_97_to_23['hours'] = normalise(df, 'hours', year=1997, industry_column='industry_id')\n"
     ]
    }
   ],
   "source": [
    "# quantity indices\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "q_vars_dict_2 = {\n",
    "    'GO': ['gross_output_quantity'],\n",
    "    'CAP': cap_qty_list,\n",
    "    'LAB': lab_qty_list,\n",
    "    'II': ii_qty_list}\n",
    "\n",
    "v_vars_dict_2 = {\n",
    "    'GO': ['GO'],\n",
    "    'CAP': cap_comp_list,\n",
    "    'LAB': lab_comp_list,\n",
    "    'II': ii_comp_list}\n",
    "\n",
    "for variable in core_variables:\n",
    "    q_vars = q_vars_dict_2[variable]\n",
    "    v_vars = v_vars_dict_2[variable]\n",
    "    df[f'{variable}_QI'] = tornqvist_index(df, q_vars, v_vars, industry_column='industry_id')\n",
    "\n",
    "df['year'] = df['year'].astype(int)\n",
    "\n",
    "df_qi_97_to_23 = df[qi_variables + ['year', 'industry_id', 'VA', 'hours']] \n",
    "df_qi_97_to_23['hours'] = normalise(df, 'hours', year=1997, industry_column='industry_id')\n",
    "df_qi_97_to_23 = df_qi_97_to_23.set_index(['year', 'industry_id']).sort_index(level=['industry_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66343798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate industries\n",
    "\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI', 'hours']\n",
    "\n",
    "df_qi_97_to_23 = aggregate_industries(df_qi_97_to_23)\n",
    "\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI']\n",
    "\n",
    "df_qi_97_to_23 = df_qi_97_to_23.drop(columns=['VA'])\n",
    "\n",
    "df_97_to_23_hours = df_qi_97_to_23['hours'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0511be",
   "metadata": {},
   "source": [
    "# 5. Chaining 1947-2016 with 1997-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "252d29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_47_to_96_hours = df_47_to_16_hours[df_47_to_16_hours.index.get_level_values('year').astype(int) <= 1997]\n",
    "qi_variables = ['hours']\n",
    "df_47_to_23_hours = chain(df_47_to_96_hours, df_97_to_23_hours, 1997)\n",
    "qi_variables = ['GO_QI', 'CAP_QI', 'LAB_QI', 'II_QI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8305e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qi_47_to_96 = df_qi_47_to_16[df_qi_47_to_16.index.get_level_values('year').astype(int) <= 1997]\n",
    "\n",
    "df_qi_47_to_23 = chain(df_qi_47_to_96, df_qi_97_to_23, 1997)\n",
    "\n",
    "df_qi_47_to_23 = df_qi_47_to_23.reset_index()\n",
    "\n",
    "df_qi_47_to_23['year'] = df_qi_47_to_23['year'].astype(int)\n",
    "\n",
    "for qi in qi_variables:\n",
    "   df_qi_47_to_23[qi] = normalise(df_qi_47_to_23, qi, year=2009, industry_column='industry_id')\n",
    "\n",
    "df_qi_47_to_23 = df_qi_47_to_23.set_index(['year', 'industry_id']).sort_index(level=['industry_id'])\n",
    "\n",
    "df_47_to_23 = pd.merge(df_nominal_47_to_23[core_variables], df_qi_47_to_23[qi_variables],  left_index=True, right_index=True, how='inner').round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d106c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_47_to_23 = pd.merge(df_47_to_23, df_47_to_23_hours, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d43293",
   "metadata": {},
   "source": [
    "# 6. Calculating constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18643efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant values\n",
    "\n",
    "df_47_to_23 = df_47_to_23.reset_index()\n",
    "\n",
    "for variable in core_variables:\n",
    "    df_47_to_23[f'REAL_{variable}'] = constant_values(df_47_to_23, variable, 2009)\n",
    "\n",
    "df_47_to_23 = df_47_to_23.set_index(['year', 'industry_id']).sort_index(level=['industry_id'])\n",
    "\n",
    "df_47_to_23 = df_47_to_23[core_variables + constant_variables + qi_variables + ['hours']]\n",
    "\n",
    "df = df_47_to_23.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112da32",
   "metadata": {},
   "source": [
    "# 7. Building productivity indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24831958",
   "metadata": {},
   "source": [
    "### 7.1 Nominal Value Added\n",
    "$$\n",
    "P_{V A}(t) Q_{V A}(t) = P_Y (t) Q_Y (t) - P_{II} (t) Q_{II} (t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "285ef3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VA'] = df['GO'] - df['II']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a4cbc",
   "metadata": {},
   "source": [
    "Nominal Value Added share of Gross Output:\n",
    "$$\n",
    "\\nu_{V A}(t) = \\frac{P_{V A}(t) Q_{V A}(t)}{P_Y (t) Q_Y (t)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc613dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VA/GO'] = df['VA'] / df['GO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0047b87",
   "metadata": {},
   "source": [
    "### 7.2 Value Added index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe21eff",
   "metadata": {},
   "source": [
    "To compute a value added quantity index, we start from the definition of a Tornqvist Quantity Index for total output $Y$\n",
    "\n",
    "$$\n",
    "\\Delta \\ln Q_Y (t) = \\bar{\\nu}_{V A} (t) \\Delta \\ln Q_{VA}(t)   + \\bar{\\nu}_{II} (t) \\Delta \\ln Q_{II} (t)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\Delta \\ln X(t) = \\ln X(t) - \\ln X(t - 1)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\bar{\\nu}_X(t) = 0.5 \\times \\left( \\frac{P_X(t) Q_X(t)}{P_Y (t) Q_Y (t)} + \\frac{P_X(t - 1) Q_X(t - 1)}{P_Y (t - 1) Q_Y (t - 1)} \\right).\n",
    "$$\n",
    "\n",
    "In the formula above $\\bar{\\nu}_{VA}(t)$ and $\\bar{\\nu}_{II}(t)$ represent the Tornqvist weights for $(VA)$ and intermediate inputs $(II)$, respectively.\n",
    "\n",
    "Re arranging terms, we get:\n",
    "\n",
    "$$\n",
    "\\Delta \\ln Q_{VA}(t) = \\frac{\\Delta \\ln Q_Y (t) - \\bar{\\nu}_{II} (t) \\Delta \\ln Q_{II} (t)}{\\bar{\\nu}_{V A} (t)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b7582",
   "metadata": {},
   "source": [
    "#### 7.2.1 Compute log differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a61a6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ln_REAL_GO'] = np.log(df['REAL_GO'])\n",
    "df['ln_REAL_II'] = np.log(df['REAL_II'])\n",
    "\n",
    "df['delta_ln_REAL_GO'] = delta(df, 'ln_REAL_GO')\n",
    "df['delta_ln_REAL_II'] = delta(df, 'ln_REAL_II')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601dae9",
   "metadata": {},
   "source": [
    "#### 7.2.2 Compute the Tornqvist Output Weights\n",
    "\n",
    "$$\n",
    "\\bar{\\nu}_X(t) = 0.5 \\times \\left( \\frac{P_X(t) Q_X(t)}{P_Y (t) Q_Y (t)} + \\frac{P_X(t - 1) Q_X(t - 1)}{P_Y (t - 1) Q_Y (t - 1)} \\right)\n",
    "$$\n",
    "\n",
    "where X is either nominal VA or nominal II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "110f81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['II/GO'] = df['II'] / df['GO']\n",
    "\n",
    "df['VA/GO_lag'] = lag(df, 'VA/GO')\n",
    "df['II/GO_lag'] = lag(df, 'II/GO')\n",
    "\n",
    "df['VA_tornqvist_GO_share'] = 0.5 * (df['VA/GO'] + df['VA/GO_lag'])\n",
    "df['II_tornqvist_GO_share'] = 0.5 * (df['II/GO'] + df['II/GO_lag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab08361",
   "metadata": {},
   "source": [
    "#### 7.2.3 Compute the log change of the Value Added quantity index\n",
    "\n",
    "$$\n",
    "\\Delta \\ln Q_{VA}(t) = \\frac{\\Delta \\ln Q_Y (t) - \\bar{\\nu}_{II} (t) \\Delta \\ln Q_{II} (t)}{\\bar{\\nu}_{V A} (t)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fefc0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_ln_VA_QI'] = ((df['delta_ln_REAL_GO'] - (df['II_tornqvist_GO_share']*df['delta_ln_REAL_II']))/df['VA_tornqvist_GO_share'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86461156",
   "metadata": {},
   "source": [
    "### 7.3 Labour Productivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be29c4ae",
   "metadata": {},
   "source": [
    "For now, our measure of labor quantity is real compensation of employees. It follows that:\n",
    "LP_VA:\n",
    "$$\n",
    "\\Delta \\ln LP(t) = \\Delta \\ln Q_{VA}(t) - \\Delta \\ln Q_L(t)\n",
    "$$\n",
    "LP_GO:\n",
    "$$\n",
    "\\Delta \\ln LP(t) = \\Delta \\ln Q_{GO}(t) - \\Delta \\ln Q_L(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "777c3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ln_REAL_LAB'] = np.log(df['REAL_LAB'])\n",
    "df['delta_ln_REAL_LAB'] = delta(df, 'ln_REAL_LAB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b0920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ln_hours'] = np.log(df['hours'])\n",
    "df['delta_ln_hours'] = delta(df, 'ln_hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17660705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_ln_LP_VA'] = (df['delta_ln_VA_QI'] - df['delta_ln_hours'])\n",
    "df['delta_ln_LP_GO'] = (df['delta_ln_REAL_GO'] - df['delta_ln_hours'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fee178",
   "metadata": {},
   "source": [
    "### 7.4 Total Factor Productivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803eee6",
   "metadata": {},
   "source": [
    "Assuming that VA is produced by combining capital and labor services and TFP via a Tornqvist Index, we can back out log change in TFP using\n",
    "$$\n",
    "\\Delta \\ln TFP(t) = \\Delta \\ln Q_{VA}(t) - \\bar{\\psi}_L(t) \\Delta \\ln Q_L(t) - \\bar{\\psi}_K(t) \\Delta \\ln Q_K(t),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\bar{\\psi}_X(t) = 0.5 \\times \\left( \\frac{P_X(t) Q_X(t)}{P_{VA}(t) Q_{VA}(t)} + \\frac{P_X(t-1) Q_X(t-1)}{P_{VA}(t-1) Q_{VA}(t-1)} \\right)\n",
    "$$\n",
    "\n",
    "and X is either nominal LAB (L) or nominal CAP (K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67873f",
   "metadata": {},
   "source": [
    "#### 7.4.1 Tornqvist VA and GO share\n",
    "\n",
    "$$\n",
    "\\bar{\\psi}_X(t) = 0.5 \\times \\left( \\frac{P_X(t) Q_X(t)}{P_{VA}(t) Q_{VA}(t)} + \\frac{P_X(t-1) Q_X(t-1)}{P_{VA}(t-1) Q_{VA}(t-1)} \\right)\n",
    "$$\n",
    "\n",
    "where X is either nominal $LAB (L)$ or nominal $CAP (K)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb057518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LAB/VA'] = df['LAB'] / df['VA']\n",
    "df['CAP/VA'] = df['CAP'] / df['VA']\n",
    "df['LAB/VA_lag'] = lag(df, 'LAB/VA')\n",
    "df['CAP/VA_lag'] = lag(df, 'CAP/VA')\n",
    "df['L_tornqvist_VA_share'] = 0.5 * (df['LAB/VA'] + df['LAB/VA_lag'])\n",
    "df['CAP_tornqvist_VA_share'] = 0.5 * (df['CAP/VA'] + df['CAP/VA_lag'])\n",
    "\n",
    "df['LAB/GO'] = df['LAB'] / df['GO']\n",
    "df['CAP/GO'] = df['CAP'] / df['GO']\n",
    "df['LAB/GO_lag'] = lag(df, 'LAB/GO')\n",
    "df['CAP/GO_lag'] = lag(df, 'CAP/GO')\n",
    "df['L_tornqvist_GO_share'] = 0.5 * (df['LAB/GO'] + df['LAB/GO_lag'])\n",
    "df['CAP_tornqvist_GO_share'] = 0.5 * (df['CAP/GO'] + df['CAP/GO_lag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf21b91",
   "metadata": {},
   "source": [
    "#### 7.4.2 Real capital; logged and log difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "016a4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ln_REAL_CAP'] = np.log(df['REAL_CAP'])\n",
    "df['delta_ln_REAL_CAP'] = delta(df, 'ln_REAL_CAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d571a6a7",
   "metadata": {},
   "source": [
    "#### 7.4.3 TFP growth rate\n",
    "TFP_VA:\n",
    "$$\n",
    "\\Delta \\ln TFP(t) = \\Delta \\ln Q_{VA}(t) - \\bar{\\psi}_L(t) \\Delta \\ln Q_L(t) - \\bar{\\psi}_K(t) \\Delta \\ln Q_K(t)\n",
    "$$\n",
    "\n",
    "TFP_GO:\n",
    "$$\n",
    "\\Delta \\ln TFP(t) = \\Delta \\ln Q_{GO}(t) - \\bar{\\psi}_L(t) \\Delta \\ln Q_L(t) - \\bar{\\psi}_K(t) \\Delta \\ln Q_K(t) - \\bar{\\psi}_{II}(t) \\Delta \\ln Q_{II}(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a40d7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_ln_TFP_VA'] = (df['delta_ln_VA_QI'] - (df['L_tornqvist_VA_share']*df['delta_ln_REAL_LAB']) - (df['CAP_tornqvist_VA_share']*df['delta_ln_REAL_CAP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ea5fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_ln_TFP_GO'] = (df['delta_ln_REAL_GO'] - (df)['L_tornqvist_GO_share']*df['delta_ln_REAL_LAB'] - (df['CAP_tornqvist_GO_share']*df['delta_ln_REAL_CAP']) - (df['II_tornqvist_GO_share']*df['delta_ln_REAL_II']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aedaa3",
   "metadata": {},
   "source": [
    "### 7.5 Recover the TFP, LP and VA indexes, then normalise to 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62366c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover index function \n",
    "\n",
    "def recover_index(df, index_name):\n",
    "    df['ln_' + index_name] = df.groupby('industry_id')['delta_ln_' + index_name].cumsum().fillna(0)\n",
    "    df[index_name] = np.exp(df['ln_' + index_name])\n",
    "    df[index_name] *= 100\n",
    "    return df[index_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78fdb918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "\n",
    "for variable in productivity_index_variables:\n",
    "    df[variable] = recover_index(df, variable)\n",
    "    df[variable] = normalise(df, variable, year=2009, industry_column='industry_id')\n",
    "df['VA_QI'] = recover_index(df, 'VA_QI')\n",
    "df['VA_QI'] = normalise(df, 'VA_QI', year=2009, industry_column='industry_id')\n",
    "\n",
    "df = df.set_index(['year', 'industry_id']).sort_index(level=['industry_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc66b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[core_variables + ['VA'] + constant_variables + qi_variables + ['VA_QI'] + productivity_index_variables].round(4)\n",
    "df_complete = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80703810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GO</th>\n",
       "      <th>CAP</th>\n",
       "      <th>LAB</th>\n",
       "      <th>II</th>\n",
       "      <th>VA</th>\n",
       "      <th>REAL_GO</th>\n",
       "      <th>REAL_CAP</th>\n",
       "      <th>REAL_LAB</th>\n",
       "      <th>REAL_II</th>\n",
       "      <th>GO_QI</th>\n",
       "      <th>CAP_QI</th>\n",
       "      <th>LAB_QI</th>\n",
       "      <th>II_QI</th>\n",
       "      <th>VA_QI</th>\n",
       "      <th>TFP_GO</th>\n",
       "      <th>TFP_VA</th>\n",
       "      <th>LP_GO</th>\n",
       "      <th>LP_VA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>industry_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <th>1</th>\n",
       "      <td>31299.230</td>\n",
       "      <td>9744.228</td>\n",
       "      <td>10039.002</td>\n",
       "      <td>11516.0</td>\n",
       "      <td>19783.230</td>\n",
       "      <td>85420.7366</td>\n",
       "      <td>58072.4257</td>\n",
       "      <td>175614.4448</td>\n",
       "      <td>71655.4180</td>\n",
       "      <td>28.0331</td>\n",
       "      <td>91.8022</td>\n",
       "      <td>350.6423</td>\n",
       "      <td>37.4430</td>\n",
       "      <td>18.6973</td>\n",
       "      <td>34.2724</td>\n",
       "      <td>9.9743</td>\n",
       "      <td>4.7605</td>\n",
       "      <td>3.1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <th>1</th>\n",
       "      <td>35560.695</td>\n",
       "      <td>11602.553</td>\n",
       "      <td>11443.142</td>\n",
       "      <td>12515.0</td>\n",
       "      <td>23045.695</td>\n",
       "      <td>93240.3033</td>\n",
       "      <td>62451.0323</td>\n",
       "      <td>169739.8335</td>\n",
       "      <td>71305.9727</td>\n",
       "      <td>30.5993</td>\n",
       "      <td>98.7240</td>\n",
       "      <td>338.9127</td>\n",
       "      <td>37.2604</td>\n",
       "      <td>21.4984</td>\n",
       "      <td>37.0196</td>\n",
       "      <td>11.2514</td>\n",
       "      <td>5.2976</td>\n",
       "      <td>3.7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <th>1</th>\n",
       "      <td>29746.566</td>\n",
       "      <td>6988.223</td>\n",
       "      <td>11310.343</td>\n",
       "      <td>11448.0</td>\n",
       "      <td>18298.566</td>\n",
       "      <td>90564.3063</td>\n",
       "      <td>62630.1163</td>\n",
       "      <td>170840.0710</td>\n",
       "      <td>70636.9362</td>\n",
       "      <td>29.7211</td>\n",
       "      <td>99.0071</td>\n",
       "      <td>341.1095</td>\n",
       "      <td>36.9108</td>\n",
       "      <td>20.6429</td>\n",
       "      <td>35.9716</td>\n",
       "      <td>10.7512</td>\n",
       "      <td>5.2764</td>\n",
       "      <td>3.6647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <th>1</th>\n",
       "      <td>31972.906</td>\n",
       "      <td>9193.447</td>\n",
       "      <td>10284.459</td>\n",
       "      <td>12495.0</td>\n",
       "      <td>19477.906</td>\n",
       "      <td>95692.0309</td>\n",
       "      <td>63096.6455</td>\n",
       "      <td>158602.6833</td>\n",
       "      <td>74804.0615</td>\n",
       "      <td>31.4039</td>\n",
       "      <td>99.7446</td>\n",
       "      <td>316.6756</td>\n",
       "      <td>39.0883</td>\n",
       "      <td>21.7807</td>\n",
       "      <td>38.0812</td>\n",
       "      <td>11.7999</td>\n",
       "      <td>5.8552</td>\n",
       "      <td>4.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <th>1</th>\n",
       "      <td>37255.438</td>\n",
       "      <td>11954.302</td>\n",
       "      <td>10551.134</td>\n",
       "      <td>14750.0</td>\n",
       "      <td>22505.438</td>\n",
       "      <td>94865.6469</td>\n",
       "      <td>67334.6291</td>\n",
       "      <td>150626.2118</td>\n",
       "      <td>79642.3284</td>\n",
       "      <td>31.1327</td>\n",
       "      <td>106.4441</td>\n",
       "      <td>300.7493</td>\n",
       "      <td>41.6165</td>\n",
       "      <td>20.6164</td>\n",
       "      <td>36.6797</td>\n",
       "      <td>11.0925</td>\n",
       "      <td>6.0988</td>\n",
       "      <td>4.0387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         GO        CAP        LAB       II         VA  \\\n",
       "year industry_id                                                        \n",
       "1947 1            31299.230   9744.228  10039.002  11516.0  19783.230   \n",
       "1948 1            35560.695  11602.553  11443.142  12515.0  23045.695   \n",
       "1949 1            29746.566   6988.223  11310.343  11448.0  18298.566   \n",
       "1950 1            31972.906   9193.447  10284.459  12495.0  19477.906   \n",
       "1951 1            37255.438  11954.302  10551.134  14750.0  22505.438   \n",
       "\n",
       "                     REAL_GO    REAL_CAP     REAL_LAB     REAL_II    GO_QI  \\\n",
       "year industry_id                                                             \n",
       "1947 1            85420.7366  58072.4257  175614.4448  71655.4180  28.0331   \n",
       "1948 1            93240.3033  62451.0323  169739.8335  71305.9727  30.5993   \n",
       "1949 1            90564.3063  62630.1163  170840.0710  70636.9362  29.7211   \n",
       "1950 1            95692.0309  63096.6455  158602.6833  74804.0615  31.4039   \n",
       "1951 1            94865.6469  67334.6291  150626.2118  79642.3284  31.1327   \n",
       "\n",
       "                    CAP_QI    LAB_QI    II_QI    VA_QI   TFP_GO   TFP_VA  \\\n",
       "year industry_id                                                           \n",
       "1947 1             91.8022  350.6423  37.4430  18.6973  34.2724   9.9743   \n",
       "1948 1             98.7240  338.9127  37.2604  21.4984  37.0196  11.2514   \n",
       "1949 1             99.0071  341.1095  36.9108  20.6429  35.9716  10.7512   \n",
       "1950 1             99.7446  316.6756  39.0883  21.7807  38.0812  11.7999   \n",
       "1951 1            106.4441  300.7493  41.6165  20.6164  36.6797  11.0925   \n",
       "\n",
       "                   LP_GO   LP_VA  \n",
       "year industry_id                  \n",
       "1947 1            4.7605  3.1752  \n",
       "1948 1            5.2976  3.7220  \n",
       "1949 1            5.2764  3.6647  \n",
       "1950 1            5.8552  4.0610  \n",
       "1951 1            6.0988  4.0387  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bd5ec",
   "metadata": {},
   "source": [
    "# 8. Aggregated by economy, services and goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebea2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tqvist_byfactor_bycat(df, weighted_variables):\n",
    "    df = df.copy()\n",
    "    by_factor_df = pd.DataFrame()\n",
    "\n",
    "    for variable in weighted_variables:  \n",
    "        industries = df['industry_id'].unique()\n",
    "\n",
    "        va_series = []\n",
    "        ti_series = []\n",
    "\n",
    "        for industry in industries:\n",
    "            va_col_name = f'{industry}_VA'\n",
    "            va_df = (df.loc[df['industry_id'] == industry][['year', 'VA']].rename(columns={'VA': va_col_name}).set_index('year'))\n",
    "\n",
    "            ti_col_name = f'{industry}_{variable}'\n",
    "            ti_df = (df.loc[df['industry_id'] == industry][['year', variable]].rename(columns={variable: ti_col_name}).set_index('year'))\n",
    "\n",
    "            va_series.append(va_df)\n",
    "            ti_series.append(ti_df)\n",
    "\n",
    "        va_ti_df = pd.DataFrame()\n",
    "        va_ti_df['year'] = df['year'].unique()\n",
    "        va_ti_df = va_ti_df.sort_values('year').reset_index(drop=True)\n",
    "        va_ti_df = pd.concat([va_ti_df.set_index('year')] + va_series + ti_series, axis=1).reset_index()\n",
    "\n",
    "        q_vars = [col for col in va_ti_df.columns if col.endswith(variable)]\n",
    "        v_vars = [col for col in va_ti_df.columns if col.endswith('VA')]\n",
    "        va_ti_df[variable] = tornqvist_index(va_ti_df, q_vars, v_vars)\n",
    "\n",
    "        if by_factor_df.empty:\n",
    "            by_factor_df = va_ti_df[['year', variable]]\n",
    "        else:\n",
    "            by_factor_df = by_factor_df.merge(va_ti_df[['year', variable]], on='year', how='outer')\n",
    "\n",
    "    return by_factor_df.set_index('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bef0f86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n",
      "C:\\Users\\Selim Elbadri\\AppData\\Local\\Temp\\ipykernel_42936\\464079509.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'w_{col}'] = df[col] / total_v\n"
     ]
    }
   ],
   "source": [
    "df_ew = df.copy().reset_index()\n",
    "df_ew = df_ew[df_ew['year'].astype(int) >= 1963]\n",
    "\n",
    "df_ew = df_ew[df_ew['industry_id'].between(1, 63)].copy()\n",
    "df_goods = df_ew[df_ew['industry_id'].between(1, 26)].copy()\n",
    "df_services = df_ew[df_ew['industry_id'].between(27, 63)].copy()\n",
    "df_research_services = df_ew[df_ew['industry_id'].isin([39, 42, 43, 44, 47, 48, 49])].copy()\n",
    "df_non_research_services = df_ew[df_ew['industry_id'].isin([27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])].copy()\n",
    "\n",
    "weighted_variables = qi_variables + ['VA_QI'] + productivity_index_variables\n",
    "sum_cols = core_variables + ['VA'] + constant_variables \n",
    "\n",
    "df_dict = {\n",
    "    'total': df_ew,\n",
    "    'goods': df_goods,\n",
    "    'services': df_services,\n",
    "    'research_services': df_research_services,\n",
    "    'non_research_services': df_non_research_services\n",
    "}\n",
    "\n",
    "summed_data = {}\n",
    "for key, df in df_dict.items():\n",
    "    df_sum = df.copy()\n",
    "    df_sum[sum_cols] = df_sum.groupby('year')[sum_cols].transform('sum')\n",
    "    df_sum = df_sum[['year'] + sum_cols].drop_duplicates(subset='year').set_index('year')\n",
    "    summed_data[key] = df_sum\n",
    "\n",
    "for key in ['total', 'goods', 'services', 'research_services', 'non_research_services']:\n",
    "    df_dict[key] = tqvist_byfactor_bycat(df_dict[key], weighted_variables)\n",
    "    df_dict[key] = pd.merge(summed_data[key], df_dict[key], how='inner', left_index=True, right_index=True)\n",
    "\n",
    "ew_df = df_dict['total']\n",
    "goods_df = df_dict['goods']\n",
    "services_df = df_dict['services']\n",
    "research_services_df = df_dict['research_services']\n",
    "non_research_services_df = df_dict['non_research_services']\n",
    "\n",
    "for df in [ew_df, goods_df, services_df, research_services_df, non_research_services_df]:\n",
    "    df.reset_index(inplace=True)\n",
    "    for variable in weighted_variables:\n",
    "        base_value = df.loc[df['year'] == 2009, variable].iloc[0]\n",
    "        df[variable] = (df[variable] / base_value) * 100\n",
    "    df.set_index(['year'], inplace=True)\n",
    "    df[:] = df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4248d9a",
   "metadata": {},
   "source": [
    "# 9. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24a837be",
   "metadata": {},
   "outputs": [],
   "source": [
    "industries_info = (\n",
    "    pd.DataFrame(list(industry_id_map.items()), columns=['industry_name', 'industry_id'])\n",
    "    .sort_values('industry_id')\n",
    "    .reset_index(drop=True))\n",
    "\n",
    "variables_dictionary = {\n",
    "    '*': 'Note: variables with * are normalised to 2009 = 100',\n",
    "    'GO': 'Nominal Gross Output',\n",
    "    'CAP': 'Nominal Capital',\n",
    "    'LAB': 'Nominal Labor',\n",
    "    'II': 'Nominal Intermediate Inputs',\n",
    "    'VA': 'Nominal Value Added',\n",
    "    'REAL_GO*': 'Real Gross Output',\n",
    "    'REAL_CAP*': 'Real Capital',\n",
    "    'REAL_LAB*': 'Real Labor',\n",
    "    'REAL_II*': 'Real Intermediate Inputs',\n",
    "    'GO_QI*': 'Gross Output Quantity Index',\n",
    "    'CAP_QI*': 'Capital Quantity Index',\n",
    "    'LAB_QI*': 'Labor Quantity Index',\n",
    "    'II_QI*': 'Intermediate Inputs Quantity Index',\n",
    "    'VA_QI*': 'Value Added Quantity Index',\n",
    "    'TFP_GO*': 'Total Factor Productivity Index (GO)',\n",
    "    'TFP_VA*': 'Total Factor Productivity Index (VA)',\n",
    "    'LP_GO*': 'Labor Productivity Index (GO)',\n",
    "    'LP_VA*': 'Labor Productivity Index (VA)',\n",
    "}\n",
    "\n",
    "variables_info = pd.DataFrame(\n",
    "    list(variables_dictionary.items()), \n",
    "    columns=['variable_name', 'variable_description'])\n",
    "\n",
    "aggregate_industries_dictionary = {\n",
    "    'Period': '1947-2023',\n",
    "    '2936': 'Industries 29-36',\n",
    "    '3740': 'Industries 37-40',\n",
    "    '4144': 'Industries 41-44',\n",
    "    '4749': 'Industries 47-49',\n",
    "    '5152': 'Industries 51-52',\n",
    "    '5456': 'Industries 54-56',\n",
    "    '5758': 'Industries 57-58'\n",
    "}\n",
    "\n",
    "aggregate_industries_info = pd.DataFrame(\n",
    "    list(aggregate_industries_dictionary.items()),\n",
    "    columns=['industry_group', 'industry_ids']\n",
    ")\n",
    "\n",
    "file_path = os.path.join(export_file_path, \"df_47_to_23.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    industries_info.to_excel(writer, sheet_name='Info', index=False, startrow=1, startcol=1)\n",
    "    aggregate_industries_info.to_excel(writer, sheet_name='Info', index=False, startrow=1, startcol=4)\n",
    "    variables_info.to_excel(writer, sheet_name='Info', index=False, startrow=1, startcol=7)\n",
    "    df_complete.to_excel(writer, sheet_name='Data', index=True)\n",
    "    ew_df.to_excel(writer, sheet_name='Aggregate', index=True)\n",
    "    goods_df.to_excel(writer, sheet_name='Goods_Aggregate', index=True)\n",
    "    services_df.to_excel(writer, sheet_name='Services_Aggregate', index=True)\n",
    "    research_services_df.to_excel(writer, sheet_name='Research_Services_Aggregate', index=True)\n",
    "    non_research_services_df.to_excel(writer, sheet_name='Non_Research_Services_Aggregate', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
