{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d233a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06977ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set directory for input files\n",
    "import_file_path = rf\"..\\\\Input\"\n",
    "export_file_path = rf\"..\\\\Output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc93b70",
   "metadata": {},
   "source": [
    "# 2. Functions & Industry Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6a03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute log-diff and drop original variable\n",
    "def dlog(df, var, group_col='indnum', time_col='yr', base_year=None):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values([group_col, time_col])\n",
    "    newvar = f'dlog_{var}'.replace(' ', '_')\n",
    "\n",
    "    #Compute log difference\n",
    "    df[newvar] = df.groupby(group_col)[var].transform(lambda x: np.log(x).diff())\n",
    "\n",
    "    #Force NaN for base_year or first available year in each group\n",
    "    if base_year is not None:\n",
    "        df.loc[df[time_col] == base_year, newvar] = np.nan\n",
    "    else:\n",
    "        min_years = df.groupby(group_col)[time_col].transform('min')\n",
    "        df.loc[df[time_col] == min_years, newvar] = np.nan\n",
    "\n",
    "    #Drop original variable\n",
    "    return df.drop(columns=[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21dc9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that turns growth rates into an index\n",
    "def index_generation(df, variables):\n",
    "    df = df.copy()\n",
    "    for var_g in variables:\n",
    "        #Create the cumulative sum of growth rates, starting from 0 in base year\n",
    "        def transform_group(group):\n",
    "            #Find the first non-NaN year (first growth rate)\n",
    "            first_valid_idx = group[var_g].first_valid_index()\n",
    "            if first_valid_idx is None:\n",
    "                return pd.Series(np.nan, index=group.index)\n",
    "            \n",
    "            first_valid_year = group.loc[first_valid_idx, 'yr']\n",
    "            base_year = first_valid_year - 1\n",
    "            \n",
    "            #Initialize log_X with NaN\n",
    "            log_X = pd.Series(np.nan, index=group.index)\n",
    "            \n",
    "            #Set base year to 0\n",
    "            log_X[group['yr'] == base_year] = 0\n",
    "            \n",
    "            #For years >= first_valid_year, compute cumulative sum\n",
    "            mask = group['yr'] >= first_valid_year\n",
    "            if mask.any():\n",
    "                #Get growth rates from first_valid_year onward\n",
    "                growth_rates = group.loc[mask, var_g]\n",
    "                #Compute cumulative sum starting from 0\n",
    "                cumulative_sum = growth_rates.cumsum()\n",
    "                #Assign to log_X\n",
    "                log_X.loc[mask] = cumulative_sum\n",
    "            \n",
    "            return log_X\n",
    "        \n",
    "        #Apply the transformation group-wise\n",
    "        log_X = df.groupby('indnum').apply(transform_group).reset_index(level=0, drop=True)\n",
    "        \n",
    "        #Convert to level index\n",
    "        df[var_g.replace('_g', '')] = np.exp(log_X)\n",
    "    \n",
    "    return df.drop(columns=variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03919b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebase_indices(df, vars_to_rebase, base_year, id_var='indnum', time_var='yr'):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    for var in vars_to_rebase:\n",
    "        #Get the value in the base year for each id\n",
    "        base_values = df_new.loc[df_new[time_var] == base_year, [id_var, var]]\n",
    "        base_values = base_values.rename(columns={var: f'{var}_base'})\n",
    "        \n",
    "        #Merge the base year values into the main dataframe\n",
    "        df_new = df_new.merge(base_values, on=id_var, how='left')\n",
    "        \n",
    "        #Rebase\n",
    "        df_new[var] = df_new[var] / df_new[f'{var}_base']\n",
    "        \n",
    "        #Drop temporary column\n",
    "        df_new = df_new.drop(columns=[f'{var}_base'])\n",
    "    \n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220dcd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Industry aggregations for 1947-1963\n",
    "aggregate_groups = {\n",
    "    2936: list(range(29, 37)),\n",
    "    3740: list(range(37, 41)),\n",
    "    4144: list(range(41, 45)),\n",
    "    4749: list(range(47, 50)),\n",
    "    5152: list(range(51, 53)),\n",
    "    5456: list(range(54, 57)),\n",
    "    5758: list(range(57, 59))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e13753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the desired column order\n",
    "order_1963to2023 = ['indnum','yr', 'GO', 'VA', 'CAP', 'LAB', 'II','GO_QI','CAPIT','CAPSOFT', 'CAPRD','CAPART','CAPOTH','CAPIT_QI',\n",
    "    'CAPSOFT_QI','CAPRD_QI','CAPART_QI','CAPOTH_QI','LABCOL','LABNCOL','LABCOL_QI','LABNCOL_QI','II_QI','IIEN', 'IIMT','IISERV', 'IIEN_QI', 'IIMT_QI', 'IISERV_QI','HRS_QI'\n",
    "]\n",
    "order_1947to2023 = ['indnum','yr', 'GO', 'VA', 'CAP', 'LAB', 'II','GO_QI','CAPIT','CAPSOFT', 'CAPRD','CAPART','CAPOTH','CAPIT_QI',\n",
    "    'CAPSOFT_QI','CAPRD_QI','CAPART_QI','CAPOTH_QI','LABCOL','LABNCOL','LABCOL_QI','LABNCOL_QI','II_QI','HRS_QI'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cecf30f",
   "metadata": {},
   "source": [
    "# 3. Cleaning BEA-BLS Experimental Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4628fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify needed variables\n",
    "experimental_vars          = ['yr','indnum','goqi.','iiqi.','vlcol.','vln.','vkit.','vksoft.','vkRD.',\n",
    "    'vkart.','vkoth.','qkit.','qks.','qkrd.','qka.','qko.','hrs','qlindexcol_merge.', 'qlindexn_merge.']\n",
    "\n",
    "#Extract datasheets from BEA-BLS Integrated Industry-Level Production Account (Eldridge et al., 2020)\n",
    "df_experimental_1947to1963 = pd.read_excel(os.path.join(import_file_path, 'industry-production-account-experimental.xlsx'), \n",
    "    sheet_name='1947-1963', skiprows=1, usecols=experimental_vars)\n",
    "df_experimental_1963to2016 = pd.read_excel(os.path.join(import_file_path, 'industry-production-account-experimental.xlsx'),\n",
    "    sheet_name='1963-2016', skiprows=1, usecols=experimental_vars)\n",
    "\n",
    "#Quantity indices to be log-differenced\n",
    "q_indices = ['goqi.','iiqi.','qkit.','qks.','qkrd.','qka.','qko.','qlindexcol_merge.','qlindexn_merge.','hrs']\n",
    "\n",
    "#Generate log-difference for quantity indices in both sheets\n",
    "for v in q_indices:\n",
    "    df_experimental_1947to1963 = dlog(df_experimental_1947to1963, v, base_year=1947)\n",
    "\n",
    "for v in q_indices:\n",
    "    df_experimental_1963to2016 = dlog(df_experimental_1963to2016, v, base_year=1963)\n",
    "\n",
    "#Rename variable names for both dataframes\n",
    "experimental_renaming = {\n",
    "    'vkit.': 'CAPIT','vksoft.': 'CAPSOFT', 'vkRD.': 'CAPRD','vkart.': 'CAPART','vkoth.': 'CAPOTH','vlcol.': 'LABCOL','vln.': 'LABNCOL',\n",
    "    'dlog_goqi.': 'GO_QI_g','dlog_iiqi.': 'II_QI_g','dlog_qkit.': 'CAPIT_QI_g','dlog_qks.': 'CAPSOFT_QI_g','dlog_qkrd.': 'CAPRD_QI_g',\n",
    "    'dlog_qka.': 'CAPART_QI_g','dlog_qko.': 'CAPOTH_QI_g','dlog_qlindexcol_merge.': 'LABCOL_QI_g','dlog_qlindexn_merge.': 'LABNCOL_QI_g',\n",
    "    'dlog_hrs': 'HRS_QI_g'\n",
    "}\n",
    "df_experimental_1963to2016 = df_experimental_1963to2016.rename(columns=experimental_renaming)\n",
    "df_experimental_1947to1963 = df_experimental_1947to1963.rename(columns=experimental_renaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00240c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restrict BEA-BLS Experimental to 1997 (for nominal variables) and to 1998 (for growth variables)\n",
    "nom_var     = ['CAPIT','CAPSOFT', 'CAPRD', 'CAPART', 'CAPOTH', 'LABCOL', 'LABNCOL']\n",
    "growth_var  = ['CAPIT_QI_g','CAPSOFT_QI_g', 'CAPRD_QI_g', 'CAPART_QI_g', 'CAPOTH_QI_g', 'LABCOL_QI_g', 'LABNCOL_QI_g', 'HRS_QI_g','GO_QI_g','II_QI_g']\n",
    "               \n",
    "#Nominal variables stop after 1996\n",
    "df_experimental_1963to2016 = df_experimental_1963to2016.copy()\n",
    "for v in nom_var:\n",
    "    df_experimental_1963to2016.loc[(df_experimental_1963to2016['yr'] < 1963) | (df_experimental_1963to2016['yr'] > 1996),v] = np.nan\n",
    "\n",
    "#Growth variables stop after 1997\n",
    "for v in growth_var:\n",
    "    df_experimental_1963to2016.loc[(df_experimental_1963to2016['yr'] < 1963) | (df_experimental_1963to2016['yr'] > 1997),v] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a514fe1e",
   "metadata": {},
   "source": [
    "# 4. Cleaning WK2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5888c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify needed variables\n",
    "klems_vars = ['year', 'industry', 'gross output', 'capital', 'labor', 'intermediate']\n",
    "\n",
    "#Extract the required datasheets from US KLEMS, March 2017 (Jorgenson et al., 2017)\n",
    "df_klems = pd.read_excel(os.path.join(import_file_path, 'usa_wk_mar_2017.xlsx'), sheet_name='KLEMdata', skiprows=1, usecols=klems_vars)\n",
    "\n",
    "#Rename panel identifiers to be consistent with df_experimental\n",
    "df_klems.rename(columns={'industry': 'indnum','year': 'yr'}, inplace=True)\n",
    "\n",
    "#Rename variables to be consistent with KLEMS literature\n",
    "df_klems.rename(columns={'gross output': 'GO','capital': 'CAP','labor': 'LAB','intermediate': 'II'}, inplace=True)\n",
    "\n",
    "#Generate value add\n",
    "df_klems[\"VA\"] = df_klems[\"GO\"] - df_klems[\"II\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f142c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For consistency with other datasets, consolidate federal government and state & local government from 2 industries each to 1 industry each\n",
    "federal_inds          = [62, 63]\n",
    "state_local_inds      = [64, 65]\n",
    "\n",
    "#Sum nominal variables for indnum 62/63\n",
    "federal               = df_klems[df_klems['indnum'].isin(federal_inds)].groupby('yr', as_index=False)[['GO', 'CAP', 'LAB', 'II', 'VA']].sum()\n",
    "\n",
    "#Sum nominal variables for indnum 64/65\n",
    "state_local           = df_klems[df_klems['indnum'].isin(state_local_inds)].groupby('yr', as_index=False)[['GO', 'CAP', 'LAB', 'II', 'VA']].sum()\n",
    "\n",
    "federal['indnum']     = 62           #Consolidated Federal government indnum = 62\n",
    "state_local['indnum'] = 63           #Consolidated state & local indnum = 63\n",
    "\n",
    "#Remove the original rows and append new rows\n",
    "df_klems              = df_klems[~df_klems['indnum'].isin(federal_inds + state_local_inds)]\n",
    "df_klems              = pd.concat([df_klems, federal, state_local], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b5fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build panel for broad industries starting from 1947-\n",
    "df_klems_1947to2014 = (\n",
    "    df_klems.assign(indnum=df_klems['indnum'].replace({i:new for new, olds in aggregate_groups.items() for i in olds}))\n",
    "    .groupby(['yr','indnum'], as_index=False)[['GO', 'CAP', 'LAB', 'II', 'VA']].sum())\n",
    "df_klems_1947to2014 = df_klems_1947to2014.sort_values(['indnum','yr']).reset_index(drop=True)\n",
    "\n",
    "#Build panel for finer industries starting 1963-\n",
    "df_klems_1963to2014 = df_klems[df_klems['yr'] >= 1963]\n",
    "df_klems_1963to2014 = df_klems_1963to2014.sort_values(['indnum','yr']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1cc42c",
   "metadata": {},
   "source": [
    "# 5. Cleaning BEA-BLS Capital Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc06f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of sheets to extract data from\n",
    "capital_sheets = [\n",
    "    'Capital_Art_Quantity','Capital_R&D_Quantity','Capital_IT_Quantity','Capital_Other_Quantity','Capital_Software_Quantity',\n",
    "    'Capital_Art Compensation', 'Capital_R&D Compensation','Capital_IT Compensation','Capital_Other Compensation','Capital_Software Compensation',\n",
    "    'Labor_Col_Quantity','Labor_NoCol_Quantity','Labor_Col Compensation','Labor_NoCol Compensation',\n",
    "    'Energy_Quantity','Materials_Quantity','Services_Quantity','Energy Compensation', \n",
    "    'Materials Compensation','Service Compensation','Gross Output', 'Gross Output_Quantity', 'Labor Hours_Quantity'\n",
    "]\n",
    "\n",
    "#Extract industry-level from BEA-BLS Integrated Industry-Level Production Account (Eldridge et al., 2025)\n",
    "long_data = []\n",
    "for sheet in capital_sheets:\n",
    "    df_tmp = pd.read_excel(os.path.join(import_file_path, 'industry-production-account-capital.xlsx'), sheet_name=sheet, header=1).dropna(how='all')\n",
    "    df_tmp = df_tmp.rename(columns={df_tmp.columns[0]: 'industry_description'})\n",
    "    df_tmp = df_tmp.melt(id_vars='industry_description', var_name='year', value_name=sheet)\n",
    "    long_data.append(df_tmp)\n",
    "df_capital_1997to2023 = reduce(lambda l, r: pd.merge(l, r, on=['industry_description','year'], how='outer'), long_data)\n",
    "df_capital_1997to2023 = df_capital_1997to2023.rename(columns={'year':'yr','industry_description':'Description'})\n",
    "\n",
    "#Create a sequential `indnum` for each unique Description with existing order\n",
    "order                           = df_capital_1997to2023['Description'].drop_duplicates().tolist()\n",
    "mapping                         = {desc: i+1 for i, desc in enumerate(order)}\n",
    "df_capital_1997to2023['indnum'] = df_capital_1997to2023['Description'].map(mapping).astype('Int64')\n",
    "df_capital_1997to2023['yr']     = pd.to_numeric(df_capital_1997to2023['yr'], errors='coerce')\n",
    "df_capital_1997to2023           = df_capital_1997to2023.drop(columns='Description')\n",
    "\n",
    "#Move panel identifiers first\n",
    "cols                            = ['indnum', 'yr'] + [c for c in df_capital_1997to2023.columns if c not in ['indnum', 'yr']]\n",
    "df_capital_1997to2023           = df_capital_1997to2023[cols]\n",
    "df_capital_1997to2023           = df_capital_1997to2023.sort_values(['indnum', 'yr']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b4f8e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log difference the quantity variables\n",
    "q_indices             = ['Gross Output_Quantity','Capital_IT_Quantity','Capital_Software_Quantity','Capital_R&D_Quantity',\n",
    "                         'Capital_Art_Quantity','Capital_Other_Quantity','Labor_Col_Quantity','Labor_NoCol_Quantity',\n",
    "                         'Labor Hours_Quantity','Energy_Quantity','Materials_Quantity','Services_Quantity']\n",
    "\n",
    "for v in q_indices:\n",
    "    df_capital_1997to2023 = dlog(df_capital_1997to2023, v, base_year=1997)\n",
    "\n",
    "#Rename df_capital_1997to2023 variables to match df_experimental variable names\n",
    "capital_dictionary = {\n",
    "    'Gross Output': 'GO','Capital_IT Compensation': 'CAPIT','Capital_Software Compensation': 'CAPSOFT',\n",
    "    'Capital_R&D Compensation': 'CAPRD','Capital_Art Compensation': 'CAPART','Capital_Other Compensation': 'CAPOTH',\n",
    "    'Labor_Col Compensation': 'LABCOL','Labor_NoCol Compensation': 'LABNCOL','dlog_Gross_Output_Quantity': 'GO_QI_g',\n",
    "    'dlog_Capital_IT_Quantity': 'CAPIT_QI_g','dlog_Capital_Software_Quantity': 'CAPSOFT_QI_g','dlog_Capital_R&D_Quantity': 'CAPRD_QI_g',\n",
    "    'dlog_Capital_Art_Quantity': 'CAPART_QI_g','dlog_Capital_Other_Quantity': 'CAPOTH_QI_g','dlog_Labor_Col_Quantity': 'LABCOL_QI_g',\n",
    "    'dlog_Labor_NoCol_Quantity': 'LABNCOL_QI_g','dlog_Labor_Hours_Quantity': 'HRS_QI_g','dlog_Energy_Quantity': 'IIEN_QI_g',\n",
    "    'dlog_Materials_Quantity': 'IIMT_QI_g','dlog_Services_Quantity': 'IISERV_QI_g','Service Compensation': 'IISERV',\n",
    "    'Materials Compensation': 'IIMT','Energy Compensation': 'IIEN'\n",
    "}\n",
    "\n",
    "#Rename variables using capital_dictionary\n",
    "rename_dict                = {k: v for k, v in capital_dictionary.items() if k in df_capital_1997to2023.columns}\n",
    "df_capital_1997to2023      = df_capital_1997to2023.rename(columns=rename_dict)\n",
    "df_capital_1997to2023_exGO = df_capital_1997to2023.drop('GO', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e13f6a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use BEA-BLS Capital to compute nominal variables GO, II, LAB, CAP (needed for 2015-, both for broad industries and finer industries)\n",
    "df_capital_nominal = (df_capital_1997to2023[df_capital_1997to2023['yr'] >= 2015].copy())\n",
    "\n",
    "nominal_agg_map = {\n",
    "    'GO' : ['GO'],\n",
    "    'CAP': ['CAPIT', 'CAP_SOFT', 'CAPRD', 'CAPART', 'CAPOTH'],\n",
    "    'LAB': ['LABNCOL', 'LABCOL'],\n",
    "    'II' : ['IISERV', 'IIMT', 'IIEN']\n",
    "}\n",
    "for newvar, cols in nominal_agg_map.items():\n",
    "    cols_present                   = [c for c in cols if c in df_capital_nominal.columns]\n",
    "    df_capital_nominal[newvar]     = df_capital_nominal[cols_present].apply(pd.to_numeric, errors='coerce').sum(axis=1, min_count=1)\n",
    "\n",
    "#Keep nominal variables 2015 or after for 1963 industry classification and generate VA\n",
    "df_capital_nominal_start1963       = df_capital_nominal[['yr','indnum','GO','II','LAB','CAP']].reset_index(drop=True)\n",
    "df_capital_nominal_start1963[\"VA\"] = df_klems[\"GO\"] - df_klems[\"II\"]\n",
    "\n",
    "#Keep nominal variables 2015 or after for 1947 industry classification\n",
    "df_capital_nominal_start1947       = (\n",
    "    df_capital_nominal_start1963.copy()\n",
    "    .assign(indnum=lambda d: d['indnum'].map({i:new for new, old in aggregate_groups.items() for i in old}).fillna(d['indnum']).astype('Int64'))\n",
    "    .groupby(['yr','indnum'], as_index=False)[['GO','II','LAB','CAP','VA']].sum())\n",
    "df_capital_nominal_start1947       = df_capital_nominal_start1947.sort_values(by=['indnum', 'yr']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96e4301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Summary \n",
    "##In the cleaning stage, we have prepared 7 relevant dataframes:\n",
    "#df_experimental_1963to2016   : Quantity indices and compensation for factor components (1963-2016)\n",
    "#df_capital_1997to2023_exGO   : Quantity indices and compensation for factor components (1997-2023)\n",
    "#df_klems_1963to2014          : Nominal GO, II, CAP, LAB, VA for 1963 industry aggregations (1963-2014)\n",
    "#df_capital_nominal_start1963 : Nominal GO, II, CAP, LAB, VA for 1963 industry aggregations (2015-2023)\n",
    "\n",
    "#df_klems_1947to2014          : Nominal GO, II, CAP, LAB, VA for 1947 industry aggregations (1947-2014)\n",
    "#df_capital_nominal_start1947 : Nominal GO, II, CAP, LAB, VA for 1947 industry aggregations (2015-2023)\n",
    "#df_experimental_1947to1963   : Quantity indices and compensation for factor components (1947-1963)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a5564",
   "metadata": {},
   "source": [
    "# 6. Merging the Datasets for 1963-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8691f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append df_klems_1963to2014 & df_capital_nominal_start1963 to create 1963-2023 GO, II, CAP, LAB, VA panel\n",
    "df_nom_1963to2023 = pd.concat([df_klems_1963to2014, df_capital_nominal_start1963], ignore_index=True)\n",
    "df_nom_1963to2023 = df_nom_1963to2023.sort_values(by=['indnum', 'yr']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00bd83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging quantity indices and compensation for factor components (1963-1996/97 & 1997/98-2023)  \n",
    "all_cols                   = list(set(df_experimental_1963to2016.columns).union(df_capital_1997to2023_exGO.columns))\n",
    "df_experimental_1963to2016 = df_experimental_1963to2016.reindex(columns=all_cols)\n",
    "df_capital_1997to2023_exGO = df_capital_1997to2023_exGO.reindex(columns=all_cols)\n",
    "\n",
    "#Merge both datasets together\n",
    "df_extended                = pd.merge(df_experimental_1963to2016,df_capital_1997to2023_exGO,on=[\"indnum\", \"yr\"], how=\"outer\", suffixes=(\"_exp\", \"_cap\"))\n",
    "\n",
    "#If same column appears twice, then coalesce\n",
    "for col in all_cols:\n",
    "    if col + \"_exp\" in df_extended and col + \"_cap\" in df_extended:\n",
    "        df_extended[col] = df_extended[col + \"_exp\"].combine_first(df_extended[col + \"_cap\"])\n",
    "        df_extended      = df_extended.drop(columns=[col + \"_exp\", col + \"_cap\"])\n",
    "\n",
    "#Sort by indnum-yr\n",
    "df_extended                = df_extended.sort_values(by=[\"indnum\", \"yr\"]).reset_index(drop=True)\n",
    "\n",
    "#Chain the growth rates into indices\n",
    "growth_vars = [\n",
    "    \"GO_QI_g\", \"CAPIT_QI_g\", \"CAPSOFT_QI_g\", \"CAPRD_QI_g\", \"CAPART_QI_g\", \"CAPOTH_QI_g\",\n",
    "    \"LABCOL_QI_g\", \"LABNCOL_QI_g\", \"II_QI_g\", \"IISERV_QI_g\", \"IIMT_QI_g\", \"IIEN_QI_g\", \n",
    "    \"HRS_QI_g\"\n",
    "]\n",
    "df_qindices_1963to2023     = index_generation(df_extended, growth_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d301a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge panel data with nominal values and panel data with quantity indices and compensation for factor components\n",
    "df_1963to2023 = pd.merge(df_nom_1963to2023,df_qindices_1963to2023,on=['indnum', 'yr'],how='inner') \n",
    "df_1963to2023 = df_1963to2023.sort_values(by=['indnum', 'yr']).reset_index(drop=True)\n",
    "\n",
    "#Rebase to year 2000\n",
    "quantity_vars = [\n",
    "    \"GO_QI\", \"CAPIT_QI\", \"CAPSOFT_QI\", \"CAPRD_QI\", \"CAPART_QI\", \"CAPOTH_QI\",\n",
    "    \"LABCOL_QI\", \"LABNCOL_QI\", \"II_QI\", \"IIEN_QI\",\"IIMT_QI\",\"IISERV_QI\",\"HRS_QI\"\n",
    "]\n",
    "df_1963to2023 = rebase_indices(df_1963to2023, vars_to_rebase=quantity_vars, base_year=2000)\n",
    "df_1963to2023 = df_1963to2023[order_1963to2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88795176",
   "metadata": {},
   "source": [
    "# 7. Merging the Datasets for 1947-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef0dd6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a panel dataset for nominal values 1947-1963 (merging KLEMS (1947-2014) and BEA-BLS Capital (2015-2023))\n",
    "all_cols                     = list(set(df_klems_1947to2014.columns).union(df_capital_nominal_start1947.columns))\n",
    "df_klems_1947to2014          = df_klems_1947to2014.reindex(columns=all_cols)\n",
    "df_capital_nominal_start1947 = df_capital_nominal_start1947.reindex(columns=all_cols)\n",
    "\n",
    "#Append both datasets\n",
    "df_nom_1947to2023            = pd.concat([df_klems_1947to2014, df_capital_nominal_start1947], ignore_index=True)\n",
    "\n",
    "#Sort by panel identifiers (indnum, yr)\n",
    "df_nom_1947to2023            = df_nom_1947to2023.sort_values(by=['indnum', 'yr']).reset_index(drop=True)\n",
    "other_cols                   = [c for c in df_nom_1947to2023.columns if c not in [\"indnum\", \"yr\"]]\n",
    "df_nom_1947to2023            = df_nom_1947to2023[[\"indnum\", \"yr\"] + other_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f993705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain the growth rates into indices\n",
    "growth_vars = [\n",
    "    \"GO_QI_g\", \"CAPIT_QI_g\", \"CAPSOFT_QI_g\", \"CAPRD_QI_g\", \"CAPART_QI_g\", \"CAPOTH_QI_g\",\n",
    "    \"LABCOL_QI_g\", \"LABNCOL_QI_g\", \"II_QI_g\", \"HRS_QI_g\"\n",
    "]\n",
    "df_qindices_1947to2023     = index_generation(df_experimental_1947to1963, growth_vars)\n",
    "\n",
    "#Merge df_nom_1947to2023 with df_qindices_1947to2023\n",
    "df_1947to2023   = pd.merge(df_nom_1947to2023,df_qindices_1947to2023,on=[\"indnum\", \"yr\"],how=\"outer\",suffixes=(\"_exp63\", \"_full\"))  # keeps all rows from both\n",
    "df_1947to2023   = df_1947to2023.sort_values(by=[\"indnum\", \"yr\"]).reset_index(drop=True)\n",
    "other_cols      = [c for c in df_1947to2023.columns if c not in [\"indnum\", \"yr\"]]\n",
    "df_1947to2023   = df_1947to2023[[\"indnum\", \"yr\"] + other_cols]\n",
    "\n",
    "#Rebase to year 2000\n",
    "quantity_vars = [\n",
    "    \"GO_QI\", \"CAPIT_QI\", \"CAPSOFT_QI\", \"CAPRD_QI\", \"CAPART_QI\", \"CAPOTH_QI\",\n",
    "    \"LABCOL_QI\", \"LABNCOL_QI\", \"II_QI\", \"HRS_QI\"\n",
    "]\n",
    "df_1963to2023 = rebase_indices(df_1963to2023, vars_to_rebase=quantity_vars, base_year=2000)\n",
    "\n",
    "#Reorder variables\n",
    "df_1947to2023   = df_1947to2023[order_1947to2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797f3db",
   "metadata": {},
   "source": [
    "# 8. Combine 1947-2023 and 1963-2023 Datasets and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4af17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a variable definition DataFrame (only Variable + Description)\n",
    "var_defs = pd.DataFrame({\n",
    "\"Variable\" : ['indnum','yr', 'GO', 'VA', 'CAP', 'LAB', 'II','GO_QI','CAPIT','CAPSOFT', 'CAPRD','CAPART','CAPOTH','CAPIT_QI',\n",
    "    'CAPSOFT_QI','CAPRD_QI','CAPART_QI','CAPOTH_QI','LABCOL','LABNCOL','LABCOL_QI','LABNCOL_QI','II_QI','IIEN', 'IIMT','IISERV', \n",
    "    'IIEN_QI', 'IIMT_QI', 'IISERV_QI','HRS_QI'],\n",
    "\n",
    "    \"Description\": [\n",
    "        \"Industry identifier\",                                  \n",
    "        \"Year\",                                                 \n",
    "        \"Nominal Gross Output\",                                 \n",
    "        \"Nominal Value Added\",                                  \n",
    "        \"Nominal Capital Compensation\",                         \n",
    "        \"Nominal Labor Compensation\",                           \n",
    "        \"Nominal Intermediate Input Compensation\",              \n",
    "        \"Output Quantity Index\",\n",
    "        \"Nominal IT Equipment Capital Compensation\",            \n",
    "        \"Nominal Software Capital Compensation\",                \n",
    "        \"Nominal R&D Capital Compensation\",                      \n",
    "        \"Nominal Entertainment Originals Capital Compensation\",  \n",
    "        \"Nominal Other Capital Compensation\",         \n",
    "        \"IT Equipment Capital Quantity Index\",        \n",
    "        \"Software Capital Quantity Index\",            \n",
    "        \"R&D Capital Quantity Index\",                 \n",
    "        \"Entertainment Originals Quantity Index\",     \n",
    "        \"Other Capital Quantity Index\",               \n",
    "        \"Nominal College Labor Compensation\",         \n",
    "        \"Nominal Non-College Labor Compensation\",     \n",
    "        \"College Labor Quantity Index\",               \n",
    "        \"Non-college Labor Quantity Index\",           \n",
    "        \"Intermediate Input Quantity Index\",          \n",
    "        \"Nominal Energy Intermediate Compensation\",   \n",
    "        \"Nominal Materials Intermediate Compensation\",\n",
    "        \"Nominal Services Intermediate Compensation\", \n",
    "        \"Energy Intermediate Input Quantity Index\", \n",
    "        \"Materials Intermediate Input Quantity Index\", \n",
    "        \"Services Intermediate Input Quantity Index\",     \n",
    "        \"Hours Quantity Index\"    \n",
    "    ]\n",
    "})\n",
    "\n",
    "#Export Excel with multiple sheets\n",
    "os.makedirs(export_file_path, exist_ok=True)\n",
    "output_file = os.path.join(export_file_path, \"cleandata_new.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "    #Sheet 1 -- Legend\n",
    "    var_defs.to_excel(writer, sheet_name=\"VariableDefinitions\", index=False)\n",
    "    \n",
    "    #Sheets 2/3 -- Data\n",
    "    df_1963to2023.to_excel(writer, sheet_name=\"1963to2023\", index=False)\n",
    "    df_1947to2023.to_excel(writer, sheet_name=\"1947to2023\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
